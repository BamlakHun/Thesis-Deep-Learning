{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow\n",
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_table(\"AOI_hitStimuli1Polygon.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Skill_level</th>\n",
       "      <th>Gaze_point_X</th>\n",
       "      <th>Gaze_point_Y</th>\n",
       "      <th>Gaze_event_duration</th>\n",
       "      <th>Fixation_point_X</th>\n",
       "      <th>Fixation_point_Y</th>\n",
       "      <th>AOI_hit_Stimuli1_Polygon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skilled</td>\n",
       "      <td>612</td>\n",
       "      <td>325</td>\n",
       "      <td>699</td>\n",
       "      <td>615</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Skilled</td>\n",
       "      <td>609</td>\n",
       "      <td>325</td>\n",
       "      <td>699</td>\n",
       "      <td>615</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skilled</td>\n",
       "      <td>611</td>\n",
       "      <td>321</td>\n",
       "      <td>699</td>\n",
       "      <td>615</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skilled</td>\n",
       "      <td>611</td>\n",
       "      <td>324</td>\n",
       "      <td>699</td>\n",
       "      <td>615</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skilled</td>\n",
       "      <td>610</td>\n",
       "      <td>327</td>\n",
       "      <td>699</td>\n",
       "      <td>615</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Skilled</td>\n",
       "      <td>611</td>\n",
       "      <td>324</td>\n",
       "      <td>699</td>\n",
       "      <td>615</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Skilled</td>\n",
       "      <td>611</td>\n",
       "      <td>324</td>\n",
       "      <td>699</td>\n",
       "      <td>615</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Skilled</td>\n",
       "      <td>614</td>\n",
       "      <td>326</td>\n",
       "      <td>699</td>\n",
       "      <td>615</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Skilled</td>\n",
       "      <td>617</td>\n",
       "      <td>327</td>\n",
       "      <td>699</td>\n",
       "      <td>615</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Skilled</td>\n",
       "      <td>612</td>\n",
       "      <td>325</td>\n",
       "      <td>699</td>\n",
       "      <td>615</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Skill_level  Gaze_point_X  Gaze_point_Y  Gaze_event_duration  \\\n",
       "0     Skilled           612           325                  699   \n",
       "1     Skilled           609           325                  699   \n",
       "2     Skilled           611           321                  699   \n",
       "3     Skilled           611           324                  699   \n",
       "4     Skilled           610           327                  699   \n",
       "5     Skilled           611           324                  699   \n",
       "6     Skilled           611           324                  699   \n",
       "7     Skilled           614           326                  699   \n",
       "8     Skilled           617           327                  699   \n",
       "9     Skilled           612           325                  699   \n",
       "\n",
       "   Fixation_point_X  Fixation_point_Y  AOI_hit_Stimuli1_Polygon  \n",
       "0               615               329                         0  \n",
       "1               615               329                         0  \n",
       "2               615               329                         0  \n",
       "3               615               329                         0  \n",
       "4               615               329                         0  \n",
       "5               615               329                         0  \n",
       "6               615               329                         0  \n",
       "7               615               329                         0  \n",
       "8               615               329                         0  \n",
       "9               615               329                         0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skilled    0.51999\n",
       "Novice     0.48001\n",
       "Name: Skill_level, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Skill_level'].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skill_level                   2\n",
       "Gaze_point_X                836\n",
       "Gaze_point_Y                850\n",
       "Gaze_event_duration         131\n",
       "Fixation_point_X            491\n",
       "Fixation_point_Y            466\n",
       "AOI_hit_Stimuli1_Polygon      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Skill_level                   2\n",
       "Gaze_point_X                836\n",
       "Gaze_point_Y                850\n",
       "Gaze_event_duration         131\n",
       "Fixation_point_X            491\n",
       "Fixation_point_Y            466\n",
       "AOI_hit_Stimuli1_Polygon      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Skill_level', 'Gaze_point_X', 'Gaze_point_Y', 'Gaze_event_duration',\n",
       "       'Fixation_point_X', 'Fixation_point_Y', 'AOI_hit_Stimuli1_Polygon'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gaze_point_X</th>\n",
       "      <th>Gaze_point_Y</th>\n",
       "      <th>Gaze_event_duration</th>\n",
       "      <th>Fixation_point_X</th>\n",
       "      <th>Fixation_point_Y</th>\n",
       "      <th>AOI_hit_Stimuli1_Polygon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28064.000000</td>\n",
       "      <td>28064.000000</td>\n",
       "      <td>28064.000000</td>\n",
       "      <td>28064.000000</td>\n",
       "      <td>28064.000000</td>\n",
       "      <td>28064.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>641.027259</td>\n",
       "      <td>301.309008</td>\n",
       "      <td>814.581564</td>\n",
       "      <td>641.770560</td>\n",
       "      <td>301.058331</td>\n",
       "      <td>0.323653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>180.952162</td>\n",
       "      <td>158.314351</td>\n",
       "      <td>838.125717</td>\n",
       "      <td>180.162423</td>\n",
       "      <td>157.974624</td>\n",
       "      <td>0.467878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>217.000000</td>\n",
       "      <td>-145.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>-140.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>266.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>598.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>263.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>775.000000</td>\n",
       "      <td>386.000000</td>\n",
       "      <td>1015.000000</td>\n",
       "      <td>777.000000</td>\n",
       "      <td>387.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1242.000000</td>\n",
       "      <td>1628.000000</td>\n",
       "      <td>3861.000000</td>\n",
       "      <td>1238.000000</td>\n",
       "      <td>1584.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gaze_point_X  Gaze_point_Y  Gaze_event_duration  Fixation_point_X  \\\n",
       "count  28064.000000  28064.000000         28064.000000      28064.000000   \n",
       "mean     641.027259    301.309008           814.581564        641.770560   \n",
       "std      180.952162    158.314351           838.125717        180.162423   \n",
       "min      217.000000   -145.000000            66.000000        246.000000   \n",
       "25%      500.000000    195.000000           266.000000        498.000000   \n",
       "50%      598.000000    263.000000           482.000000        599.000000   \n",
       "75%      775.000000    386.000000          1015.000000        777.000000   \n",
       "max     1242.000000   1628.000000          3861.000000       1238.000000   \n",
       "\n",
       "       Fixation_point_Y  AOI_hit_Stimuli1_Polygon  \n",
       "count      28064.000000              28064.000000  \n",
       "mean         301.058331                  0.323653  \n",
       "std          157.974624                  0.467878  \n",
       "min         -140.000000                  0.000000  \n",
       "25%          193.000000                  0.000000  \n",
       "50%          263.000000                  0.000000  \n",
       "75%          387.000000                  1.000000  \n",
       "max         1584.000000                  1.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gaze_point_X</th>\n",
       "      <th>Gaze_point_Y</th>\n",
       "      <th>Gaze_event_duration</th>\n",
       "      <th>Fixation_point_X</th>\n",
       "      <th>Fixation_point_Y</th>\n",
       "      <th>AOI_hit_Stimuli1_Polygon</th>\n",
       "      <th>Skill_level_Novice</th>\n",
       "      <th>Skill_level_Skilled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>612</td>\n",
       "      <td>325</td>\n",
       "      <td>699</td>\n",
       "      <td>615</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>609</td>\n",
       "      <td>325</td>\n",
       "      <td>699</td>\n",
       "      <td>615</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>611</td>\n",
       "      <td>321</td>\n",
       "      <td>699</td>\n",
       "      <td>615</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>611</td>\n",
       "      <td>324</td>\n",
       "      <td>699</td>\n",
       "      <td>615</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>610</td>\n",
       "      <td>327</td>\n",
       "      <td>699</td>\n",
       "      <td>615</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gaze_point_X  Gaze_point_Y  Gaze_event_duration  Fixation_point_X  \\\n",
       "0           612           325                  699               615   \n",
       "1           609           325                  699               615   \n",
       "2           611           321                  699               615   \n",
       "3           611           324                  699               615   \n",
       "4           610           327                  699               615   \n",
       "\n",
       "   Fixation_point_Y  AOI_hit_Stimuli1_Polygon  Skill_level_Novice  \\\n",
       "0               329                         0                   0   \n",
       "1               329                         0                   0   \n",
       "2               329                         0                   0   \n",
       "3               329                         0                   0   \n",
       "4               329                         0                   0   \n",
       "\n",
       "   Skill_level_Skilled  \n",
       "0                    1  \n",
       "1                    1  \n",
       "2                    1  \n",
       "3                    1  \n",
       "4                    1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Gaze_point_X', 'Gaze_point_Y', 'Gaze_event_duration',\n",
       "       'Fixation_point_X', 'Fixation_point_Y', 'AOI_hit_Stimuli1_Polygon',\n",
       "       'Skill_level_Novice', 'Skill_level_Skilled'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['Skill_level_Skilled', 'Gaze_point_X', 'Gaze_point_Y', 'Gaze_event_duration',\n",
    "       'Fixation_point_X', 'Fixation_point_Y', 'AOI_hit_Stimuli1_Polygon',\n",
    "       ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28064, 7)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 612,  325,  699,  615,  329,    0],\n",
       "       [ 609,  325,  699,  615,  329,    0],\n",
       "       [ 611,  321,  699,  615,  329,    0],\n",
       "       ...,\n",
       "       [ 539,  388, 1048,  534,  381,    0],\n",
       "       [ 537,  386, 1048,  534,  381,    0],\n",
       "       [ 538,  378, 1048,  534,  381,    0]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(\"Skill_level_Skilled\", axis=1, inplace=False).values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28064, 6)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Skill_level_Skilled'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22451, 6)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler , StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.21967707, -0.63053743,  0.67546166, -1.22975849, -0.57343839,\n",
       "        -0.69046941],\n",
       "       [ 0.8536996 ,  0.77439146, -0.49746681,  0.90769744,  0.72725969,\n",
       "        -0.69046941],\n",
       "       [-0.56898971, -0.56753613, -0.67543661, -0.55418952, -0.56712433,\n",
       "         1.44829008],\n",
       "       ...,\n",
       "       [ 0.08169765, -0.80064092, -0.71604716,  0.07707985, -0.78811672,\n",
       "        -0.69046941],\n",
       "       [-0.24916033, -0.59273665, -0.37802399, -0.24962973, -0.52292585,\n",
       "         1.44829008],\n",
       "       [-0.42561792, -1.02114546, -0.59660435, -0.42682815, -1.04699352,\n",
       "        -0.69046941]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22451, 6)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_11 = keras.Sequential([\n",
    "                             layers.Dense(units = 6, activation = 'relu'),\n",
    "                             layers.Dense(units = 2, activation = 'relu'),\n",
    "\n",
    "                             layers.Dense(units = 1 , activation = 'sigmoid')\n",
    "                             ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_11.build(input_shape=(None, X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 6)                 42        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 14        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59\n",
      "Trainable params: 59\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_11.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6 * 6 + 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6 * 2 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * 1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(name=\"classfication_model\")\n",
    "model.add(layers.Input(shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(units = 6 , activation = 'relu', name=\"first_layer\"))\n",
    "model.add(layers.Dense(units = 2 , activation = 'relu', name=\"second_layer\"))\n",
    "\n",
    "model.add(layers.Dense(units = 1, activation = 'sigmoid', name=\"output_layer\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classfication_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " first_layer (Dense)         (None, 6)                 42        \n",
      "                                                                 \n",
      " second_layer (Dense)        (None, 2)                 14        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59\n",
      "Trainable params: 59\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6 * 6 + 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6 * 2 + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * 1 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'first_layer/kernel:0' shape=(6, 6) dtype=float32, numpy=\n",
       " array([[ 0.5246423 ,  0.5242248 , -0.6156609 , -0.10767472, -0.589979  ,\n",
       "         -0.6313544 ],\n",
       "        [-0.26225725,  0.6221971 ,  0.25135875, -0.06400943,  0.4112411 ,\n",
       "         -0.34438628],\n",
       "        [-0.22717303, -0.52024317, -0.2830503 ,  0.669939  , -0.6299192 ,\n",
       "          0.46759027],\n",
       "        [ 0.01316619, -0.23587179, -0.1715141 , -0.4795013 ,  0.2920215 ,\n",
       "         -0.37440443],\n",
       "        [ 0.27316618,  0.60916406,  0.41277224,  0.3469488 , -0.06034636,\n",
       "          0.31505245],\n",
       "        [-0.3346898 ,  0.17221892,  0.70153767,  0.12353086, -0.41269824,\n",
       "         -0.4519575 ]], dtype=float32)>,\n",
       " <tf.Variable 'first_layer/bias:0' shape=(6,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'second_layer/kernel:0' shape=(6, 2) dtype=float32, numpy=\n",
       " array([[-0.23900628, -0.65534914],\n",
       "        [-0.28032142, -0.5535196 ],\n",
       "        [ 0.19786936,  0.22102016],\n",
       "        [-0.06117612, -0.7056171 ],\n",
       "        [ 0.77411133, -0.5881009 ],\n",
       "        [-0.15634364,  0.27489918]], dtype=float32)>,\n",
       " <tf.Variable 'second_layer/bias:0' shape=(2,) dtype=float32, numpy=array([0., 0.], dtype=float32)>,\n",
       " <tf.Variable 'output_layer/kernel:0' shape=(2, 1) dtype=float32, numpy=\n",
       " array([[0.9907521],\n",
       "        [1.391231 ]], dtype=float32)>,\n",
       " <tf.Variable 'output_layer/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs   = keras.Input(shape=(X_train.shape[1]), name= \"my_input\")\n",
    "features = layers.Dense(20, activation='relu',   name='first_layer')(inputs)\n",
    "features = layers.Dense(8, activation='relu',   name='second_layer')(features)\n",
    "outputs   = layers.Dense(1,  activation='sigmoid',name='output_layer')(features)\n",
    "model_functional = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_input (InputLayer)       [(None, 6)]               0         \n",
      "                                                                 \n",
      " first_layer (Dense)         (None, 20)                140       \n",
      "                                                                 \n",
      " second_layer (Dense)        (None, 8)                 168       \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 317\n",
      "Trainable params: 317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_functional.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.input_layer.InputLayer at 0x24a18906288>,\n",
       " <keras.layers.core.dense.Dense at 0x24a18906888>,\n",
       " <keras.layers.core.dense.Dense at 0x24a188e4ac8>,\n",
       " <keras.layers.core.dense.Dense at 0x24a188ab108>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_functional.layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = model_functional.layers[2].output\n",
    "new_output = layers.Dense(3, activation='softmax',   name='new_output_layer')(features)\n",
    "\n",
    "new_model_functional = keras.Model(inputs=inputs, outputs=[outputs, new_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " my_input (InputLayer)          [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " first_layer (Dense)            (None, 20)           140         ['my_input[0][0]']               \n",
      "                                                                                                  \n",
      " second_layer (Dense)           (None, 8)            168         ['first_layer[0][0]']            \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, 1)            9           ['second_layer[0][0]']           \n",
      "                                                                                                  \n",
      " new_output_layer (Dense)       (None, 3)            27          ['second_layer[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 344\n",
      "Trainable params: 344\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model_functional.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8 * 3 + 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classfication_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " first_layer (Dense)         (None, 6)                 42        \n",
      "                                                                 \n",
      " second_layer (Dense)        (None, 2)                 14        \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 3         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59\n",
      "Trainable params: 59\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = keras.Sequential(name=\"classification_model\")\n",
    "    model.add(layers.Input(shape=(X_train.shape[1],))) \n",
    "    model.add(layers.Dense(units = 20, activation = 'relu', name=\"first_layer\"))\n",
    "    model.add(layers.Dense(units = 8, activation = 'relu', name=\"second_layer\"))\n",
    "\n",
    "\n",
    "    model.add(layers.Dense(units = 1, activation = 'sigmoid', name=\"output_layer\"))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classification_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " first_layer (Dense)         (None, 20)                140       \n",
      "                                                                 \n",
      " second_layer (Dense)        (None, 8)                 168       \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 317\n",
      "Trainable params: 317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "build_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "176/176 [==============================] - 6s 6ms/step - loss: 0.6083 - accuracy: 0.6365 - val_loss: 0.5480 - val_accuracy: 0.7060\n",
      "Epoch 2/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7364 - val_loss: 0.4977 - val_accuracy: 0.7554\n",
      "Epoch 3/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7567 - val_loss: 0.4757 - val_accuracy: 0.7609\n",
      "Epoch 4/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7622 - val_loss: 0.4642 - val_accuracy: 0.7664\n",
      "Epoch 5/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.4587 - accuracy: 0.7691 - val_loss: 0.4570 - val_accuracy: 0.7745\n",
      "Epoch 6/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.4516 - accuracy: 0.7737 - val_loss: 0.4495 - val_accuracy: 0.7805\n",
      "Epoch 7/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.7755 - val_loss: 0.4431 - val_accuracy: 0.7812\n",
      "Epoch 8/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.4392 - accuracy: 0.7793 - val_loss: 0.4370 - val_accuracy: 0.7743\n",
      "Epoch 9/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.7801 - val_loss: 0.4340 - val_accuracy: 0.7803\n",
      "Epoch 10/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7838 - val_loss: 0.4285 - val_accuracy: 0.7787\n",
      "Epoch 11/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7836 - val_loss: 0.4248 - val_accuracy: 0.7869\n",
      "Epoch 12/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.4229 - accuracy: 0.7841 - val_loss: 0.4232 - val_accuracy: 0.7778\n",
      "Epoch 13/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.4198 - accuracy: 0.7859 - val_loss: 0.4193 - val_accuracy: 0.7846\n",
      "Epoch 14/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.4172 - accuracy: 0.7868 - val_loss: 0.4173 - val_accuracy: 0.7914\n",
      "Epoch 15/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.4147 - accuracy: 0.7881 - val_loss: 0.4141 - val_accuracy: 0.7900\n",
      "Epoch 16/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.4127 - accuracy: 0.7864 - val_loss: 0.4124 - val_accuracy: 0.7930\n",
      "Epoch 17/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.4102 - accuracy: 0.7899 - val_loss: 0.4112 - val_accuracy: 0.7830\n",
      "Epoch 18/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.4087 - accuracy: 0.7909 - val_loss: 0.4081 - val_accuracy: 0.7901\n",
      "Epoch 19/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.4066 - accuracy: 0.7902 - val_loss: 0.4097 - val_accuracy: 0.7955\n",
      "Epoch 20/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.4052 - accuracy: 0.7914 - val_loss: 0.4048 - val_accuracy: 0.7862\n",
      "Epoch 21/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.4036 - accuracy: 0.7920 - val_loss: 0.4042 - val_accuracy: 0.7957\n",
      "Epoch 22/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.4016 - accuracy: 0.7927 - val_loss: 0.4042 - val_accuracy: 0.7894\n",
      "Epoch 23/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.4006 - accuracy: 0.7925 - val_loss: 0.4019 - val_accuracy: 0.7971\n",
      "Epoch 24/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3993 - accuracy: 0.7938 - val_loss: 0.4017 - val_accuracy: 0.7889\n",
      "Epoch 25/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3982 - accuracy: 0.7929 - val_loss: 0.3984 - val_accuracy: 0.7903\n",
      "Epoch 26/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3970 - accuracy: 0.7927 - val_loss: 0.3989 - val_accuracy: 0.7971\n",
      "Epoch 27/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3962 - accuracy: 0.7954 - val_loss: 0.3980 - val_accuracy: 0.7898\n",
      "Epoch 28/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3955 - accuracy: 0.7960 - val_loss: 0.3967 - val_accuracy: 0.7912\n",
      "Epoch 29/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3943 - accuracy: 0.7964 - val_loss: 0.3956 - val_accuracy: 0.7914\n",
      "Epoch 30/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.7961 - val_loss: 0.3948 - val_accuracy: 0.7949\n",
      "Epoch 31/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3933 - accuracy: 0.7956 - val_loss: 0.3944 - val_accuracy: 0.7955\n",
      "Epoch 32/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.7976 - val_loss: 0.3938 - val_accuracy: 0.7955\n",
      "Epoch 33/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.7968 - val_loss: 0.3939 - val_accuracy: 0.7935\n",
      "Epoch 34/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3912 - accuracy: 0.7974 - val_loss: 0.3941 - val_accuracy: 0.7980\n",
      "Epoch 35/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3906 - accuracy: 0.7964 - val_loss: 0.3917 - val_accuracy: 0.7962\n",
      "Epoch 36/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3898 - accuracy: 0.7987 - val_loss: 0.3921 - val_accuracy: 0.7971\n",
      "Epoch 37/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3889 - accuracy: 0.7985 - val_loss: 0.3900 - val_accuracy: 0.7962\n",
      "Epoch 38/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3882 - accuracy: 0.7995 - val_loss: 0.3907 - val_accuracy: 0.8005\n",
      "Epoch 39/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3874 - accuracy: 0.8008 - val_loss: 0.3876 - val_accuracy: 0.7973\n",
      "Epoch 40/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3863 - accuracy: 0.8011 - val_loss: 0.3884 - val_accuracy: 0.8021\n",
      "Epoch 41/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3860 - accuracy: 0.8025 - val_loss: 0.3862 - val_accuracy: 0.7973\n",
      "Epoch 42/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3852 - accuracy: 0.8023 - val_loss: 0.3880 - val_accuracy: 0.7957\n",
      "Epoch 43/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8033 - val_loss: 0.3881 - val_accuracy: 0.7917\n",
      "Epoch 44/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3845 - accuracy: 0.8028 - val_loss: 0.3859 - val_accuracy: 0.8038\n",
      "Epoch 45/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3838 - accuracy: 0.8039 - val_loss: 0.3853 - val_accuracy: 0.8053\n",
      "Epoch 46/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3828 - accuracy: 0.8038 - val_loss: 0.3857 - val_accuracy: 0.8037\n",
      "Epoch 47/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3824 - accuracy: 0.8059 - val_loss: 0.3852 - val_accuracy: 0.7990\n",
      "Epoch 48/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3821 - accuracy: 0.8039 - val_loss: 0.3825 - val_accuracy: 0.8026\n",
      "Epoch 49/400\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.3819 - accuracy: 0.8057 - val_loss: 0.3834 - val_accuracy: 0.7980\n",
      "Epoch 50/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3808 - accuracy: 0.8050 - val_loss: 0.3831 - val_accuracy: 0.8003\n",
      "Epoch 51/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3803 - accuracy: 0.8063 - val_loss: 0.3823 - val_accuracy: 0.8046\n",
      "Epoch 52/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3796 - accuracy: 0.8062 - val_loss: 0.3814 - val_accuracy: 0.8006\n",
      "Epoch 53/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3791 - accuracy: 0.8070 - val_loss: 0.3802 - val_accuracy: 0.8055\n",
      "Epoch 54/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3782 - accuracy: 0.8077 - val_loss: 0.3805 - val_accuracy: 0.8092\n",
      "Epoch 55/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3779 - accuracy: 0.8075 - val_loss: 0.3798 - val_accuracy: 0.8067\n",
      "Epoch 56/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8080 - val_loss: 0.3793 - val_accuracy: 0.8074\n",
      "Epoch 57/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3765 - accuracy: 0.8086 - val_loss: 0.3813 - val_accuracy: 0.8074\n",
      "Epoch 58/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8085 - val_loss: 0.3793 - val_accuracy: 0.8056\n",
      "Epoch 59/400\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.3757 - accuracy: 0.8101 - val_loss: 0.3807 - val_accuracy: 0.8055\n",
      "Epoch 60/400\n",
      "176/176 [==============================] - 1s 7ms/step - loss: 0.3750 - accuracy: 0.8108 - val_loss: 0.3779 - val_accuracy: 0.8058\n",
      "Epoch 61/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3745 - accuracy: 0.8108 - val_loss: 0.3771 - val_accuracy: 0.8119\n",
      "Epoch 62/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3742 - accuracy: 0.8102 - val_loss: 0.3757 - val_accuracy: 0.8083\n",
      "Epoch 63/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3739 - accuracy: 0.8110 - val_loss: 0.3792 - val_accuracy: 0.8092\n",
      "Epoch 64/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3732 - accuracy: 0.8123 - val_loss: 0.3741 - val_accuracy: 0.8136\n",
      "Epoch 65/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3731 - accuracy: 0.8125 - val_loss: 0.3741 - val_accuracy: 0.8110\n",
      "Epoch 66/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3720 - accuracy: 0.8124 - val_loss: 0.3740 - val_accuracy: 0.8090\n",
      "Epoch 67/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3727 - accuracy: 0.8131 - val_loss: 0.3729 - val_accuracy: 0.8154\n",
      "Epoch 68/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 0.8127 - val_loss: 0.3747 - val_accuracy: 0.8104\n",
      "Epoch 69/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3714 - accuracy: 0.8147 - val_loss: 0.3748 - val_accuracy: 0.8049\n",
      "Epoch 70/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3710 - accuracy: 0.8110 - val_loss: 0.3720 - val_accuracy: 0.8129\n",
      "Epoch 71/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3706 - accuracy: 0.8148 - val_loss: 0.3723 - val_accuracy: 0.8176\n",
      "Epoch 72/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3700 - accuracy: 0.8148 - val_loss: 0.3753 - val_accuracy: 0.8113\n",
      "Epoch 73/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3697 - accuracy: 0.8133 - val_loss: 0.3705 - val_accuracy: 0.8156\n",
      "Epoch 74/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3692 - accuracy: 0.8144 - val_loss: 0.3716 - val_accuracy: 0.8156\n",
      "Epoch 75/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3686 - accuracy: 0.8164 - val_loss: 0.3715 - val_accuracy: 0.8158\n",
      "Epoch 76/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3681 - accuracy: 0.8156 - val_loss: 0.3716 - val_accuracy: 0.8179\n",
      "Epoch 77/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3681 - accuracy: 0.8157 - val_loss: 0.3710 - val_accuracy: 0.8183\n",
      "Epoch 78/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8178 - val_loss: 0.3701 - val_accuracy: 0.8169\n",
      "Epoch 79/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8169 - val_loss: 0.3698 - val_accuracy: 0.8161\n",
      "Epoch 80/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3667 - accuracy: 0.8175 - val_loss: 0.3698 - val_accuracy: 0.8206\n",
      "Epoch 81/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8185 - val_loss: 0.3695 - val_accuracy: 0.8119\n",
      "Epoch 82/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3660 - accuracy: 0.8181 - val_loss: 0.3678 - val_accuracy: 0.8186\n",
      "Epoch 83/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3654 - accuracy: 0.8181 - val_loss: 0.3687 - val_accuracy: 0.8195\n",
      "Epoch 84/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3648 - accuracy: 0.8174 - val_loss: 0.3686 - val_accuracy: 0.8129\n",
      "Epoch 85/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3645 - accuracy: 0.8190 - val_loss: 0.3684 - val_accuracy: 0.8220\n",
      "Epoch 86/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3643 - accuracy: 0.8190 - val_loss: 0.3663 - val_accuracy: 0.8161\n",
      "Epoch 87/400\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.3638 - accuracy: 0.8171 - val_loss: 0.3658 - val_accuracy: 0.8217\n",
      "Epoch 88/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3634 - accuracy: 0.8185 - val_loss: 0.3671 - val_accuracy: 0.8193\n",
      "Epoch 89/400\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.3631 - accuracy: 0.8168 - val_loss: 0.3653 - val_accuracy: 0.8234\n",
      "Epoch 90/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3628 - accuracy: 0.8194 - val_loss: 0.3662 - val_accuracy: 0.8120\n",
      "Epoch 91/400\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.3622 - accuracy: 0.8198 - val_loss: 0.3681 - val_accuracy: 0.8147\n",
      "Epoch 92/400\n",
      "176/176 [==============================] - 1s 7ms/step - loss: 0.3618 - accuracy: 0.8194 - val_loss: 0.3660 - val_accuracy: 0.8185\n",
      "Epoch 93/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3619 - accuracy: 0.8205 - val_loss: 0.3657 - val_accuracy: 0.8133\n",
      "Epoch 94/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3603 - accuracy: 0.8198 - val_loss: 0.3645 - val_accuracy: 0.8186\n",
      "Epoch 95/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3609 - accuracy: 0.8201 - val_loss: 0.3624 - val_accuracy: 0.8240\n",
      "Epoch 96/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3599 - accuracy: 0.8203 - val_loss: 0.3650 - val_accuracy: 0.8138\n",
      "Epoch 97/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3600 - accuracy: 0.8205 - val_loss: 0.3651 - val_accuracy: 0.8149\n",
      "Epoch 98/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3592 - accuracy: 0.8205 - val_loss: 0.3672 - val_accuracy: 0.8113\n",
      "Epoch 99/400\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.3591 - accuracy: 0.8204 - val_loss: 0.3642 - val_accuracy: 0.8220\n",
      "Epoch 100/400\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 0.3585 - accuracy: 0.8213 - val_loss: 0.3626 - val_accuracy: 0.8147\n",
      "Epoch 101/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3581 - accuracy: 0.8233 - val_loss: 0.3627 - val_accuracy: 0.8204\n",
      "Epoch 102/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3575 - accuracy: 0.8230 - val_loss: 0.3637 - val_accuracy: 0.8279\n",
      "Epoch 103/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3567 - accuracy: 0.8225 - val_loss: 0.3612 - val_accuracy: 0.8231\n",
      "Epoch 104/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3557 - accuracy: 0.8221 - val_loss: 0.3602 - val_accuracy: 0.8238\n",
      "Epoch 105/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3547 - accuracy: 0.8240 - val_loss: 0.3658 - val_accuracy: 0.8071\n",
      "Epoch 106/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3536 - accuracy: 0.8226 - val_loss: 0.3621 - val_accuracy: 0.8147\n",
      "Epoch 107/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3527 - accuracy: 0.8239 - val_loss: 0.3571 - val_accuracy: 0.8304\n",
      "Epoch 108/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3524 - accuracy: 0.8261 - val_loss: 0.3589 - val_accuracy: 0.8261\n",
      "Epoch 109/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3512 - accuracy: 0.8240 - val_loss: 0.3634 - val_accuracy: 0.8140\n",
      "Epoch 110/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3508 - accuracy: 0.8235 - val_loss: 0.3575 - val_accuracy: 0.8311\n",
      "Epoch 111/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3504 - accuracy: 0.8246 - val_loss: 0.3601 - val_accuracy: 0.8313\n",
      "Epoch 112/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8250 - val_loss: 0.3572 - val_accuracy: 0.8206\n",
      "Epoch 113/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3491 - accuracy: 0.8271 - val_loss: 0.3559 - val_accuracy: 0.8247\n",
      "Epoch 114/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3490 - accuracy: 0.8263 - val_loss: 0.3540 - val_accuracy: 0.8254\n",
      "Epoch 115/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8257 - val_loss: 0.3541 - val_accuracy: 0.8291\n",
      "Epoch 116/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3480 - accuracy: 0.8253 - val_loss: 0.3549 - val_accuracy: 0.8265\n",
      "Epoch 117/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3476 - accuracy: 0.8257 - val_loss: 0.3537 - val_accuracy: 0.8245\n",
      "Epoch 118/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8275 - val_loss: 0.3524 - val_accuracy: 0.8291\n",
      "Epoch 119/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3472 - accuracy: 0.8262 - val_loss: 0.3526 - val_accuracy: 0.8290\n",
      "Epoch 120/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3470 - accuracy: 0.8276 - val_loss: 0.3525 - val_accuracy: 0.8268\n",
      "Epoch 121/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3464 - accuracy: 0.8266 - val_loss: 0.3542 - val_accuracy: 0.8322\n",
      "Epoch 122/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3460 - accuracy: 0.8257 - val_loss: 0.3520 - val_accuracy: 0.8281\n",
      "Epoch 123/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3454 - accuracy: 0.8282 - val_loss: 0.3547 - val_accuracy: 0.8254\n",
      "Epoch 124/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.8284 - val_loss: 0.3531 - val_accuracy: 0.8263\n",
      "Epoch 125/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3453 - accuracy: 0.8273 - val_loss: 0.3505 - val_accuracy: 0.8322\n",
      "Epoch 126/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3447 - accuracy: 0.8280 - val_loss: 0.3528 - val_accuracy: 0.8240\n",
      "Epoch 127/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3449 - accuracy: 0.8299 - val_loss: 0.3485 - val_accuracy: 0.8308\n",
      "Epoch 128/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3438 - accuracy: 0.8300 - val_loss: 0.3496 - val_accuracy: 0.8325\n",
      "Epoch 129/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8289 - val_loss: 0.3507 - val_accuracy: 0.8243\n",
      "Epoch 130/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3437 - accuracy: 0.8293 - val_loss: 0.3476 - val_accuracy: 0.8338\n",
      "Epoch 131/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3433 - accuracy: 0.8291 - val_loss: 0.3498 - val_accuracy: 0.8325\n",
      "Epoch 132/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3429 - accuracy: 0.8299 - val_loss: 0.3485 - val_accuracy: 0.8302\n",
      "Epoch 133/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3429 - accuracy: 0.8298 - val_loss: 0.3496 - val_accuracy: 0.8240\n",
      "Epoch 134/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3426 - accuracy: 0.8303 - val_loss: 0.3506 - val_accuracy: 0.8316\n",
      "Epoch 135/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3423 - accuracy: 0.8292 - val_loss: 0.3556 - val_accuracy: 0.8211\n",
      "Epoch 136/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3423 - accuracy: 0.8279 - val_loss: 0.3471 - val_accuracy: 0.8338\n",
      "Epoch 137/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3415 - accuracy: 0.8291 - val_loss: 0.3472 - val_accuracy: 0.8341\n",
      "Epoch 138/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3415 - accuracy: 0.8300 - val_loss: 0.3483 - val_accuracy: 0.8268\n",
      "Epoch 139/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3418 - accuracy: 0.8293 - val_loss: 0.3481 - val_accuracy: 0.8299\n",
      "Epoch 140/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3411 - accuracy: 0.8307 - val_loss: 0.3475 - val_accuracy: 0.8325\n",
      "Epoch 141/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3408 - accuracy: 0.8307 - val_loss: 0.3468 - val_accuracy: 0.8286\n",
      "Epoch 142/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8309 - val_loss: 0.3450 - val_accuracy: 0.8373\n",
      "Epoch 143/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3409 - accuracy: 0.8317 - val_loss: 0.3459 - val_accuracy: 0.8343\n",
      "Epoch 144/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3403 - accuracy: 0.8311 - val_loss: 0.3464 - val_accuracy: 0.8320\n",
      "Epoch 145/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3405 - accuracy: 0.8313 - val_loss: 0.3477 - val_accuracy: 0.8316\n",
      "Epoch 146/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3401 - accuracy: 0.8317 - val_loss: 0.3453 - val_accuracy: 0.8306\n",
      "Epoch 147/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3400 - accuracy: 0.8311 - val_loss: 0.3467 - val_accuracy: 0.8336\n",
      "Epoch 148/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8336 - val_loss: 0.3518 - val_accuracy: 0.8185\n",
      "Epoch 149/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.8312 - val_loss: 0.3515 - val_accuracy: 0.8249\n",
      "Epoch 150/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3389 - accuracy: 0.8317 - val_loss: 0.3497 - val_accuracy: 0.8247\n",
      "Epoch 151/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3380 - accuracy: 0.8323 - val_loss: 0.3453 - val_accuracy: 0.8331\n",
      "Epoch 152/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3384 - accuracy: 0.8315 - val_loss: 0.3469 - val_accuracy: 0.8293\n",
      "Epoch 153/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3377 - accuracy: 0.8322 - val_loss: 0.3445 - val_accuracy: 0.8286\n",
      "Epoch 154/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3376 - accuracy: 0.8331 - val_loss: 0.3424 - val_accuracy: 0.8357\n",
      "Epoch 155/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3374 - accuracy: 0.8341 - val_loss: 0.3459 - val_accuracy: 0.8356\n",
      "Epoch 156/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3375 - accuracy: 0.8351 - val_loss: 0.3440 - val_accuracy: 0.8284\n",
      "Epoch 157/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3370 - accuracy: 0.8336 - val_loss: 0.3451 - val_accuracy: 0.8283\n",
      "Epoch 158/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3368 - accuracy: 0.8347 - val_loss: 0.3460 - val_accuracy: 0.8267\n",
      "Epoch 159/400\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.3368 - accuracy: 0.8343 - val_loss: 0.3466 - val_accuracy: 0.8215\n",
      "Epoch 160/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3367 - accuracy: 0.8348 - val_loss: 0.3444 - val_accuracy: 0.8324\n",
      "Epoch 161/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3364 - accuracy: 0.8356 - val_loss: 0.3464 - val_accuracy: 0.8308\n",
      "Epoch 162/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3362 - accuracy: 0.8352 - val_loss: 0.3428 - val_accuracy: 0.8359\n",
      "Epoch 163/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3360 - accuracy: 0.8347 - val_loss: 0.3508 - val_accuracy: 0.8325\n",
      "Epoch 164/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3365 - accuracy: 0.8356 - val_loss: 0.3411 - val_accuracy: 0.8334\n",
      "Epoch 165/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3360 - accuracy: 0.8350 - val_loss: 0.3406 - val_accuracy: 0.8377\n",
      "Epoch 166/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3358 - accuracy: 0.8350 - val_loss: 0.3415 - val_accuracy: 0.8377\n",
      "Epoch 167/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3355 - accuracy: 0.8350 - val_loss: 0.3413 - val_accuracy: 0.8363\n",
      "Epoch 168/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3348 - accuracy: 0.8374 - val_loss: 0.3411 - val_accuracy: 0.8372\n",
      "Epoch 169/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3351 - accuracy: 0.8355 - val_loss: 0.3435 - val_accuracy: 0.8340\n",
      "Epoch 170/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8373 - val_loss: 0.3412 - val_accuracy: 0.8375\n",
      "Epoch 171/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8372 - val_loss: 0.3405 - val_accuracy: 0.8352\n",
      "Epoch 172/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3345 - accuracy: 0.8368 - val_loss: 0.3447 - val_accuracy: 0.8309\n",
      "Epoch 173/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3346 - accuracy: 0.8367 - val_loss: 0.3409 - val_accuracy: 0.8375\n",
      "Epoch 174/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3340 - accuracy: 0.8361 - val_loss: 0.3437 - val_accuracy: 0.8259\n",
      "Epoch 175/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8364 - val_loss: 0.3469 - val_accuracy: 0.8233\n",
      "Epoch 176/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3344 - accuracy: 0.8371 - val_loss: 0.3402 - val_accuracy: 0.8400\n",
      "Epoch 177/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8387 - val_loss: 0.3409 - val_accuracy: 0.8359\n",
      "Epoch 178/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3337 - accuracy: 0.8378 - val_loss: 0.3403 - val_accuracy: 0.8350\n",
      "Epoch 179/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3339 - accuracy: 0.8393 - val_loss: 0.3399 - val_accuracy: 0.8377\n",
      "Epoch 180/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8387 - val_loss: 0.3418 - val_accuracy: 0.8341\n",
      "Epoch 181/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3335 - accuracy: 0.8380 - val_loss: 0.3415 - val_accuracy: 0.8359\n",
      "Epoch 182/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3334 - accuracy: 0.8387 - val_loss: 0.3431 - val_accuracy: 0.8304\n",
      "Epoch 183/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3331 - accuracy: 0.8398 - val_loss: 0.3390 - val_accuracy: 0.8375\n",
      "Epoch 184/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3335 - accuracy: 0.8392 - val_loss: 0.3410 - val_accuracy: 0.8345\n",
      "Epoch 185/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3337 - accuracy: 0.8372 - val_loss: 0.3401 - val_accuracy: 0.8361\n",
      "Epoch 186/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3327 - accuracy: 0.8388 - val_loss: 0.3424 - val_accuracy: 0.8304\n",
      "Epoch 187/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3334 - accuracy: 0.8398 - val_loss: 0.3368 - val_accuracy: 0.8393\n",
      "Epoch 188/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3327 - accuracy: 0.8388 - val_loss: 0.3388 - val_accuracy: 0.8379\n",
      "Epoch 189/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3330 - accuracy: 0.8393 - val_loss: 0.3376 - val_accuracy: 0.8386\n",
      "Epoch 190/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3324 - accuracy: 0.8377 - val_loss: 0.3370 - val_accuracy: 0.8348\n",
      "Epoch 191/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3324 - accuracy: 0.8379 - val_loss: 0.3378 - val_accuracy: 0.8404\n",
      "Epoch 192/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3325 - accuracy: 0.8378 - val_loss: 0.3383 - val_accuracy: 0.8366\n",
      "Epoch 193/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3320 - accuracy: 0.8380 - val_loss: 0.3379 - val_accuracy: 0.8341\n",
      "Epoch 194/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3326 - accuracy: 0.8378 - val_loss: 0.3371 - val_accuracy: 0.8365\n",
      "Epoch 195/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3323 - accuracy: 0.8401 - val_loss: 0.3439 - val_accuracy: 0.8252\n",
      "Epoch 196/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8380 - val_loss: 0.3367 - val_accuracy: 0.8391\n",
      "Epoch 197/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8399 - val_loss: 0.3382 - val_accuracy: 0.8404\n",
      "Epoch 198/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3316 - accuracy: 0.8400 - val_loss: 0.3401 - val_accuracy: 0.8311\n",
      "Epoch 199/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3322 - accuracy: 0.8400 - val_loss: 0.3365 - val_accuracy: 0.8397\n",
      "Epoch 200/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3319 - accuracy: 0.8395 - val_loss: 0.3371 - val_accuracy: 0.8405\n",
      "Epoch 201/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3315 - accuracy: 0.8390 - val_loss: 0.3391 - val_accuracy: 0.8404\n",
      "Epoch 202/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3311 - accuracy: 0.8390 - val_loss: 0.3418 - val_accuracy: 0.8281\n",
      "Epoch 203/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3317 - accuracy: 0.8393 - val_loss: 0.3399 - val_accuracy: 0.8372\n",
      "Epoch 204/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3312 - accuracy: 0.8399 - val_loss: 0.3370 - val_accuracy: 0.8409\n",
      "Epoch 205/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3314 - accuracy: 0.8388 - val_loss: 0.3386 - val_accuracy: 0.8379\n",
      "Epoch 206/400\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.3313 - accuracy: 0.8402 - val_loss: 0.3352 - val_accuracy: 0.8373\n",
      "Epoch 207/400\n",
      "176/176 [==============================] - 1s 7ms/step - loss: 0.3313 - accuracy: 0.8390 - val_loss: 0.3377 - val_accuracy: 0.8377\n",
      "Epoch 208/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3311 - accuracy: 0.8393 - val_loss: 0.3366 - val_accuracy: 0.8397\n",
      "Epoch 209/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3307 - accuracy: 0.8383 - val_loss: 0.3375 - val_accuracy: 0.8379\n",
      "Epoch 210/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3309 - accuracy: 0.8391 - val_loss: 0.3448 - val_accuracy: 0.8288\n",
      "Epoch 211/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3304 - accuracy: 0.8385 - val_loss: 0.3404 - val_accuracy: 0.8290\n",
      "Epoch 212/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3310 - accuracy: 0.8393 - val_loss: 0.3378 - val_accuracy: 0.8388\n",
      "Epoch 213/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3311 - accuracy: 0.8390 - val_loss: 0.3354 - val_accuracy: 0.8381\n",
      "Epoch 214/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3307 - accuracy: 0.8393 - val_loss: 0.3405 - val_accuracy: 0.8302\n",
      "Epoch 215/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3306 - accuracy: 0.8372 - val_loss: 0.3392 - val_accuracy: 0.8311\n",
      "Epoch 216/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8409 - val_loss: 0.3395 - val_accuracy: 0.8363\n",
      "Epoch 217/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3308 - accuracy: 0.8395 - val_loss: 0.3366 - val_accuracy: 0.8398\n",
      "Epoch 218/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.8395 - val_loss: 0.3389 - val_accuracy: 0.8275\n",
      "Epoch 219/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3305 - accuracy: 0.8396 - val_loss: 0.3356 - val_accuracy: 0.8356\n",
      "Epoch 220/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3302 - accuracy: 0.8408 - val_loss: 0.3353 - val_accuracy: 0.8366\n",
      "Epoch 221/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3301 - accuracy: 0.8394 - val_loss: 0.3399 - val_accuracy: 0.8300\n",
      "Epoch 222/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3302 - accuracy: 0.8390 - val_loss: 0.3413 - val_accuracy: 0.8363\n",
      "Epoch 223/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3305 - accuracy: 0.8398 - val_loss: 0.3366 - val_accuracy: 0.8391\n",
      "Epoch 224/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3291 - accuracy: 0.8413 - val_loss: 0.3376 - val_accuracy: 0.8414\n",
      "Epoch 225/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3299 - accuracy: 0.8396 - val_loss: 0.3384 - val_accuracy: 0.8275\n",
      "Epoch 226/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3297 - accuracy: 0.8412 - val_loss: 0.3366 - val_accuracy: 0.8347\n",
      "Epoch 227/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3298 - accuracy: 0.8404 - val_loss: 0.3378 - val_accuracy: 0.8336\n",
      "Epoch 228/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3301 - accuracy: 0.8416 - val_loss: 0.3354 - val_accuracy: 0.8391\n",
      "Epoch 229/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8406 - val_loss: 0.3454 - val_accuracy: 0.8254\n",
      "Epoch 230/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3298 - accuracy: 0.8396 - val_loss: 0.3355 - val_accuracy: 0.8381\n",
      "Epoch 231/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3292 - accuracy: 0.8398 - val_loss: 0.3461 - val_accuracy: 0.8300\n",
      "Epoch 232/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3295 - accuracy: 0.8405 - val_loss: 0.3353 - val_accuracy: 0.8359\n",
      "Epoch 233/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3294 - accuracy: 0.8397 - val_loss: 0.3576 - val_accuracy: 0.8144\n",
      "Epoch 234/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3296 - accuracy: 0.8409 - val_loss: 0.3391 - val_accuracy: 0.8334\n",
      "Epoch 235/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3292 - accuracy: 0.8413 - val_loss: 0.3400 - val_accuracy: 0.8283\n",
      "Epoch 236/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3287 - accuracy: 0.8409 - val_loss: 0.3428 - val_accuracy: 0.8283\n",
      "Epoch 237/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3291 - accuracy: 0.8407 - val_loss: 0.3358 - val_accuracy: 0.8341\n",
      "Epoch 238/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3296 - accuracy: 0.8408 - val_loss: 0.3351 - val_accuracy: 0.8354\n",
      "Epoch 239/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3290 - accuracy: 0.8401 - val_loss: 0.3349 - val_accuracy: 0.8391\n",
      "Epoch 240/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3286 - accuracy: 0.8405 - val_loss: 0.3367 - val_accuracy: 0.8382\n",
      "Epoch 241/400\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.3288 - accuracy: 0.8407 - val_loss: 0.3339 - val_accuracy: 0.8372\n",
      "Epoch 242/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3287 - accuracy: 0.8405 - val_loss: 0.3412 - val_accuracy: 0.8284\n",
      "Epoch 243/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.8407 - val_loss: 0.3366 - val_accuracy: 0.8365\n",
      "Epoch 244/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3286 - accuracy: 0.8390 - val_loss: 0.3485 - val_accuracy: 0.8204\n",
      "Epoch 245/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3288 - accuracy: 0.8396 - val_loss: 0.3334 - val_accuracy: 0.8382\n",
      "Epoch 246/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8401 - val_loss: 0.3368 - val_accuracy: 0.8386\n",
      "Epoch 247/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3284 - accuracy: 0.8415 - val_loss: 0.3361 - val_accuracy: 0.8352\n",
      "Epoch 248/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3283 - accuracy: 0.8388 - val_loss: 0.3365 - val_accuracy: 0.8375\n",
      "Epoch 249/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3286 - accuracy: 0.8401 - val_loss: 0.3339 - val_accuracy: 0.8386\n",
      "Epoch 250/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3286 - accuracy: 0.8404 - val_loss: 0.3348 - val_accuracy: 0.8379\n",
      "Epoch 251/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3281 - accuracy: 0.8382 - val_loss: 0.3346 - val_accuracy: 0.8398\n",
      "Epoch 252/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8402 - val_loss: 0.3351 - val_accuracy: 0.8350\n",
      "Epoch 253/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8378 - val_loss: 0.3413 - val_accuracy: 0.8302\n",
      "Epoch 254/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8384 - val_loss: 0.3349 - val_accuracy: 0.8357\n",
      "Epoch 255/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8410 - val_loss: 0.3391 - val_accuracy: 0.8324\n",
      "Epoch 256/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3278 - accuracy: 0.8389 - val_loss: 0.3400 - val_accuracy: 0.8322\n",
      "Epoch 257/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3281 - accuracy: 0.8397 - val_loss: 0.3382 - val_accuracy: 0.8357\n",
      "Epoch 258/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3278 - accuracy: 0.8392 - val_loss: 0.3343 - val_accuracy: 0.8375\n",
      "Epoch 259/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3279 - accuracy: 0.8390 - val_loss: 0.3325 - val_accuracy: 0.8391\n",
      "Epoch 260/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3274 - accuracy: 0.8398 - val_loss: 0.3359 - val_accuracy: 0.8334\n",
      "Epoch 261/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3276 - accuracy: 0.8397 - val_loss: 0.3383 - val_accuracy: 0.8354\n",
      "Epoch 262/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3280 - accuracy: 0.8400 - val_loss: 0.3338 - val_accuracy: 0.8348\n",
      "Epoch 263/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3273 - accuracy: 0.8415 - val_loss: 0.3336 - val_accuracy: 0.8348\n",
      "Epoch 264/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3275 - accuracy: 0.8401 - val_loss: 0.3354 - val_accuracy: 0.8329\n",
      "Epoch 265/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3274 - accuracy: 0.8395 - val_loss: 0.3377 - val_accuracy: 0.8377\n",
      "Epoch 266/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3276 - accuracy: 0.8391 - val_loss: 0.3364 - val_accuracy: 0.8322\n",
      "Epoch 267/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3270 - accuracy: 0.8400 - val_loss: 0.3332 - val_accuracy: 0.8386\n",
      "Epoch 268/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3267 - accuracy: 0.8395 - val_loss: 0.3359 - val_accuracy: 0.8327\n",
      "Epoch 269/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3274 - accuracy: 0.8406 - val_loss: 0.3343 - val_accuracy: 0.8356\n",
      "Epoch 270/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3271 - accuracy: 0.8413 - val_loss: 0.3358 - val_accuracy: 0.8325\n",
      "Epoch 271/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3270 - accuracy: 0.8414 - val_loss: 0.3323 - val_accuracy: 0.8361\n",
      "Epoch 272/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8405 - val_loss: 0.3329 - val_accuracy: 0.8338\n",
      "Epoch 273/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8409 - val_loss: 0.3312 - val_accuracy: 0.8375\n",
      "Epoch 274/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8407 - val_loss: 0.3333 - val_accuracy: 0.8368\n",
      "Epoch 275/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.8406 - val_loss: 0.3330 - val_accuracy: 0.8400\n",
      "Epoch 276/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8415 - val_loss: 0.3359 - val_accuracy: 0.8354\n",
      "Epoch 277/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.8414 - val_loss: 0.3337 - val_accuracy: 0.8354\n",
      "Epoch 278/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8404 - val_loss: 0.3412 - val_accuracy: 0.8256\n",
      "Epoch 279/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8397 - val_loss: 0.3367 - val_accuracy: 0.8332\n",
      "Epoch 280/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8418 - val_loss: 0.3324 - val_accuracy: 0.8379\n",
      "Epoch 281/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8399 - val_loss: 0.3321 - val_accuracy: 0.8413\n",
      "Epoch 282/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.8413 - val_loss: 0.3369 - val_accuracy: 0.8363\n",
      "Epoch 283/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8412 - val_loss: 0.3349 - val_accuracy: 0.8352\n",
      "Epoch 284/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3261 - accuracy: 0.8408 - val_loss: 0.3357 - val_accuracy: 0.8345\n",
      "Epoch 285/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8433 - val_loss: 0.3360 - val_accuracy: 0.8356\n",
      "Epoch 286/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8410 - val_loss: 0.3340 - val_accuracy: 0.8343\n",
      "Epoch 287/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8414 - val_loss: 0.3345 - val_accuracy: 0.8341\n",
      "Epoch 288/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3258 - accuracy: 0.8421 - val_loss: 0.3363 - val_accuracy: 0.8336\n",
      "Epoch 289/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3257 - accuracy: 0.8431 - val_loss: 0.3309 - val_accuracy: 0.8414\n",
      "Epoch 290/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.8428 - val_loss: 0.3305 - val_accuracy: 0.8398\n",
      "Epoch 291/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8421 - val_loss: 0.3408 - val_accuracy: 0.8302\n",
      "Epoch 292/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3259 - accuracy: 0.8415 - val_loss: 0.3373 - val_accuracy: 0.8365\n",
      "Epoch 293/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3255 - accuracy: 0.8434 - val_loss: 0.3361 - val_accuracy: 0.8348\n",
      "Epoch 294/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3256 - accuracy: 0.8434 - val_loss: 0.3329 - val_accuracy: 0.8402\n",
      "Epoch 295/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3255 - accuracy: 0.8409 - val_loss: 0.3333 - val_accuracy: 0.8352\n",
      "Epoch 296/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3250 - accuracy: 0.8413 - val_loss: 0.3317 - val_accuracy: 0.8398\n",
      "Epoch 297/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3251 - accuracy: 0.8450 - val_loss: 0.3373 - val_accuracy: 0.8331\n",
      "Epoch 298/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3250 - accuracy: 0.8421 - val_loss: 0.3464 - val_accuracy: 0.8283\n",
      "Epoch 299/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3250 - accuracy: 0.8402 - val_loss: 0.3330 - val_accuracy: 0.8331\n",
      "Epoch 300/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.8419 - val_loss: 0.3338 - val_accuracy: 0.8389\n",
      "Epoch 301/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3249 - accuracy: 0.8430 - val_loss: 0.3340 - val_accuracy: 0.8332\n",
      "Epoch 302/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3252 - accuracy: 0.8429 - val_loss: 0.3321 - val_accuracy: 0.8404\n",
      "Epoch 303/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8408 - val_loss: 0.3329 - val_accuracy: 0.8382\n",
      "Epoch 304/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3245 - accuracy: 0.8416 - val_loss: 0.3310 - val_accuracy: 0.8382\n",
      "Epoch 305/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3249 - accuracy: 0.8417 - val_loss: 0.3322 - val_accuracy: 0.8381\n",
      "Epoch 306/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3245 - accuracy: 0.8423 - val_loss: 0.3348 - val_accuracy: 0.8332\n",
      "Epoch 307/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8421 - val_loss: 0.3341 - val_accuracy: 0.8352\n",
      "Epoch 308/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3246 - accuracy: 0.8428 - val_loss: 0.3315 - val_accuracy: 0.8345\n",
      "Epoch 309/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8456 - val_loss: 0.3365 - val_accuracy: 0.8336\n",
      "Epoch 310/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8420 - val_loss: 0.3313 - val_accuracy: 0.8393\n",
      "Epoch 311/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8428 - val_loss: 0.3323 - val_accuracy: 0.8352\n",
      "Epoch 312/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3249 - accuracy: 0.8417 - val_loss: 0.3331 - val_accuracy: 0.8363\n",
      "Epoch 313/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8427 - val_loss: 0.3288 - val_accuracy: 0.8407\n",
      "Epoch 314/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8428 - val_loss: 0.3304 - val_accuracy: 0.8411\n",
      "Epoch 315/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8423 - val_loss: 0.3303 - val_accuracy: 0.8398\n",
      "Epoch 316/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3240 - accuracy: 0.8418 - val_loss: 0.3305 - val_accuracy: 0.8395\n",
      "Epoch 317/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3243 - accuracy: 0.8436 - val_loss: 0.3341 - val_accuracy: 0.8356\n",
      "Epoch 318/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3235 - accuracy: 0.8445 - val_loss: 0.3297 - val_accuracy: 0.8368\n",
      "Epoch 319/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8433 - val_loss: 0.3311 - val_accuracy: 0.8400\n",
      "Epoch 320/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3239 - accuracy: 0.8437 - val_loss: 0.3318 - val_accuracy: 0.8409\n",
      "Epoch 321/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3239 - accuracy: 0.8436 - val_loss: 0.3333 - val_accuracy: 0.8311\n",
      "Epoch 322/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8420 - val_loss: 0.3309 - val_accuracy: 0.8373\n",
      "Epoch 323/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3237 - accuracy: 0.8431 - val_loss: 0.3293 - val_accuracy: 0.8381\n",
      "Epoch 324/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8429 - val_loss: 0.3376 - val_accuracy: 0.8313\n",
      "Epoch 325/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3237 - accuracy: 0.8432 - val_loss: 0.3278 - val_accuracy: 0.8393\n",
      "Epoch 326/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3237 - accuracy: 0.8418 - val_loss: 0.3330 - val_accuracy: 0.8356\n",
      "Epoch 327/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3239 - accuracy: 0.8434 - val_loss: 0.3321 - val_accuracy: 0.8350\n",
      "Epoch 328/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3233 - accuracy: 0.8402 - val_loss: 0.3288 - val_accuracy: 0.8395\n",
      "Epoch 329/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3234 - accuracy: 0.8435 - val_loss: 0.3293 - val_accuracy: 0.8386\n",
      "Epoch 330/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3227 - accuracy: 0.8445 - val_loss: 0.3357 - val_accuracy: 0.8332\n",
      "Epoch 331/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3233 - accuracy: 0.8415 - val_loss: 0.3368 - val_accuracy: 0.8334\n",
      "Epoch 332/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3238 - accuracy: 0.8427 - val_loss: 0.3311 - val_accuracy: 0.8395\n",
      "Epoch 333/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3229 - accuracy: 0.8433 - val_loss: 0.3322 - val_accuracy: 0.8398\n",
      "Epoch 334/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8436 - val_loss: 0.3305 - val_accuracy: 0.8379\n",
      "Epoch 335/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3233 - accuracy: 0.8432 - val_loss: 0.3368 - val_accuracy: 0.8284\n",
      "Epoch 336/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8418 - val_loss: 0.3322 - val_accuracy: 0.8320\n",
      "Epoch 337/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8433 - val_loss: 0.3328 - val_accuracy: 0.8363\n",
      "Epoch 338/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8428 - val_loss: 0.3301 - val_accuracy: 0.8388\n",
      "Epoch 339/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8426 - val_loss: 0.3337 - val_accuracy: 0.8372\n",
      "Epoch 340/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.8424 - val_loss: 0.3303 - val_accuracy: 0.8377\n",
      "Epoch 341/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3231 - accuracy: 0.8433 - val_loss: 0.3323 - val_accuracy: 0.8377\n",
      "Epoch 342/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8444 - val_loss: 0.3309 - val_accuracy: 0.8373\n",
      "Epoch 343/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3232 - accuracy: 0.8417 - val_loss: 0.3350 - val_accuracy: 0.8315\n",
      "Epoch 344/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8430 - val_loss: 0.3329 - val_accuracy: 0.8338\n",
      "Epoch 345/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8430 - val_loss: 0.3278 - val_accuracy: 0.8366\n",
      "Epoch 346/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8415 - val_loss: 0.3355 - val_accuracy: 0.8316\n",
      "Epoch 347/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3227 - accuracy: 0.8418 - val_loss: 0.3290 - val_accuracy: 0.8348\n",
      "Epoch 348/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3226 - accuracy: 0.8409 - val_loss: 0.3302 - val_accuracy: 0.8404\n",
      "Epoch 349/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8418 - val_loss: 0.3314 - val_accuracy: 0.8354\n",
      "Epoch 350/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8440 - val_loss: 0.3301 - val_accuracy: 0.8388\n",
      "Epoch 351/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8430 - val_loss: 0.3292 - val_accuracy: 0.8384\n",
      "Epoch 352/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8416 - val_loss: 0.3274 - val_accuracy: 0.8404\n",
      "Epoch 353/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3219 - accuracy: 0.8427 - val_loss: 0.3298 - val_accuracy: 0.8366\n",
      "Epoch 354/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3218 - accuracy: 0.8433 - val_loss: 0.3304 - val_accuracy: 0.8384\n",
      "Epoch 355/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8424 - val_loss: 0.3276 - val_accuracy: 0.8370\n",
      "Epoch 356/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3224 - accuracy: 0.8424 - val_loss: 0.3279 - val_accuracy: 0.8395\n",
      "Epoch 357/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3219 - accuracy: 0.8430 - val_loss: 0.3297 - val_accuracy: 0.8418\n",
      "Epoch 358/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8431 - val_loss: 0.3281 - val_accuracy: 0.8393\n",
      "Epoch 359/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3221 - accuracy: 0.8428 - val_loss: 0.3310 - val_accuracy: 0.8386\n",
      "Epoch 360/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3220 - accuracy: 0.8432 - val_loss: 0.3374 - val_accuracy: 0.8356\n",
      "Epoch 361/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3216 - accuracy: 0.8450 - val_loss: 0.3307 - val_accuracy: 0.8370\n",
      "Epoch 362/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3214 - accuracy: 0.8441 - val_loss: 0.3305 - val_accuracy: 0.8373\n",
      "Epoch 363/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3215 - accuracy: 0.8436 - val_loss: 0.3300 - val_accuracy: 0.8354\n",
      "Epoch 364/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3214 - accuracy: 0.8442 - val_loss: 0.3293 - val_accuracy: 0.8377\n",
      "Epoch 365/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3210 - accuracy: 0.8455 - val_loss: 0.3284 - val_accuracy: 0.8386\n",
      "Epoch 366/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3215 - accuracy: 0.8438 - val_loss: 0.3269 - val_accuracy: 0.8357\n",
      "Epoch 367/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3216 - accuracy: 0.8419 - val_loss: 0.3281 - val_accuracy: 0.8368\n",
      "Epoch 368/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3211 - accuracy: 0.8418 - val_loss: 0.3346 - val_accuracy: 0.8293\n",
      "Epoch 369/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8437 - val_loss: 0.3346 - val_accuracy: 0.8295\n",
      "Epoch 370/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8440 - val_loss: 0.3384 - val_accuracy: 0.8332\n",
      "Epoch 371/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3216 - accuracy: 0.8428 - val_loss: 0.3285 - val_accuracy: 0.8418\n",
      "Epoch 372/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8444 - val_loss: 0.3322 - val_accuracy: 0.8377\n",
      "Epoch 373/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8432 - val_loss: 0.3311 - val_accuracy: 0.8379\n",
      "Epoch 374/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3206 - accuracy: 0.8425 - val_loss: 0.3298 - val_accuracy: 0.8324\n",
      "Epoch 375/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3212 - accuracy: 0.8431 - val_loss: 0.3289 - val_accuracy: 0.8375\n",
      "Epoch 376/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8433 - val_loss: 0.3330 - val_accuracy: 0.8348\n",
      "Epoch 377/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8436 - val_loss: 0.3297 - val_accuracy: 0.8423\n",
      "Epoch 378/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8438 - val_loss: 0.3399 - val_accuracy: 0.8313\n",
      "Epoch 379/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3208 - accuracy: 0.8444 - val_loss: 0.3284 - val_accuracy: 0.8386\n",
      "Epoch 380/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8433 - val_loss: 0.3350 - val_accuracy: 0.8281\n",
      "Epoch 381/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8432 - val_loss: 0.3326 - val_accuracy: 0.8341\n",
      "Epoch 382/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8438 - val_loss: 0.3280 - val_accuracy: 0.8388\n",
      "Epoch 383/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3202 - accuracy: 0.8421 - val_loss: 0.3336 - val_accuracy: 0.8368\n",
      "Epoch 384/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3211 - accuracy: 0.8427 - val_loss: 0.3269 - val_accuracy: 0.8416\n",
      "Epoch 385/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8456 - val_loss: 0.3339 - val_accuracy: 0.8336\n",
      "Epoch 386/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3207 - accuracy: 0.8435 - val_loss: 0.3267 - val_accuracy: 0.8381\n",
      "Epoch 387/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3203 - accuracy: 0.8436 - val_loss: 0.3313 - val_accuracy: 0.8340\n",
      "Epoch 388/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8438 - val_loss: 0.3307 - val_accuracy: 0.8411\n",
      "Epoch 389/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3205 - accuracy: 0.8426 - val_loss: 0.3263 - val_accuracy: 0.8425\n",
      "Epoch 390/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8442 - val_loss: 0.3307 - val_accuracy: 0.8354\n",
      "Epoch 391/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8415 - val_loss: 0.3285 - val_accuracy: 0.8338\n",
      "Epoch 392/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3201 - accuracy: 0.8435 - val_loss: 0.3314 - val_accuracy: 0.8368\n",
      "Epoch 393/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8441 - val_loss: 0.3321 - val_accuracy: 0.8354\n",
      "Epoch 394/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3204 - accuracy: 0.8433 - val_loss: 0.3321 - val_accuracy: 0.8325\n",
      "Epoch 395/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3196 - accuracy: 0.8450 - val_loss: 0.3264 - val_accuracy: 0.8363\n",
      "Epoch 396/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3203 - accuracy: 0.8435 - val_loss: 0.3312 - val_accuracy: 0.8329\n",
      "Epoch 397/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3198 - accuracy: 0.8450 - val_loss: 0.3280 - val_accuracy: 0.8393\n",
      "Epoch 398/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3196 - accuracy: 0.8446 - val_loss: 0.3327 - val_accuracy: 0.8341\n",
      "Epoch 399/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3199 - accuracy: 0.8442 - val_loss: 0.3367 - val_accuracy: 0.8302\n",
      "Epoch 400/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3198 - accuracy: 0.8426 - val_loss: 0.3267 - val_accuracy: 0.8400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a18902288>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, validation_data=(X_test, y_test), epochs=400, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.320335</td>\n",
       "      <td>0.843526</td>\n",
       "      <td>0.331198</td>\n",
       "      <td>0.832888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0.319782</td>\n",
       "      <td>0.844951</td>\n",
       "      <td>0.328038</td>\n",
       "      <td>0.839302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0.319560</td>\n",
       "      <td>0.844595</td>\n",
       "      <td>0.332743</td>\n",
       "      <td>0.834135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.319924</td>\n",
       "      <td>0.844194</td>\n",
       "      <td>0.336718</td>\n",
       "      <td>0.830216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0.319821</td>\n",
       "      <td>0.842635</td>\n",
       "      <td>0.326669</td>\n",
       "      <td>0.840014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "395  0.320335  0.843526  0.331198      0.832888\n",
       "396  0.319782  0.844951  0.328038      0.839302\n",
       "397  0.319560  0.844595  0.332743      0.834135\n",
       "398  0.319924  0.844194  0.336718      0.830216\n",
       "399  0.319821  0.842635  0.326669      0.840014"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df[['loss', 'val_loss']].plot(legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_dropout():\n",
    "    model = keras.Sequential(name=\"classification_model_with_Dropout\")\n",
    "    model.add(layers.Input(shape=(X_train.shape[1],))) \n",
    "    model.add(layers.Dense(units = 20, activation = 'relu', name=\"first_layer\"))\n",
    "    model.add(layers.Dropout(rate=0.5)) \n",
    "    \n",
    "    model.add(layers.Dense(units = 8, activation = 'relu', name=\"second_layer\"))\n",
    "    model.add(layers.Dropout(rate=0.5))\n",
    "    \n",
    "    #output layer\n",
    "    model.add(layers.Dense(units = 1, activation = 'sigmoid', name=\"output_layer\"))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classification_model_with_Dropout\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " first_layer (Dense)         (None, 20)                140       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 20)                0         \n",
      "                                                                 \n",
      " second_layer (Dense)        (None, 8)                 168       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 317\n",
      "Trainable params: 317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_with_dropout = build_model_with_dropout()\n",
    "model_with_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3192 - accuracy: 0.8453 - val_loss: 0.3254 - val_accuracy: 0.8379\n",
      "Epoch 2/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3194 - accuracy: 0.8434 - val_loss: 0.3293 - val_accuracy: 0.8365\n",
      "Epoch 3/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3196 - accuracy: 0.8457 - val_loss: 0.3266 - val_accuracy: 0.8382\n",
      "Epoch 4/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3195 - accuracy: 0.8433 - val_loss: 0.3281 - val_accuracy: 0.8382\n",
      "Epoch 5/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3194 - accuracy: 0.8438 - val_loss: 0.3300 - val_accuracy: 0.8350\n",
      "Epoch 6/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3198 - accuracy: 0.8439 - val_loss: 0.3326 - val_accuracy: 0.8357\n",
      "Epoch 7/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3198 - accuracy: 0.8423 - val_loss: 0.3297 - val_accuracy: 0.8318\n",
      "Epoch 8/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3189 - accuracy: 0.8444 - val_loss: 0.3310 - val_accuracy: 0.8363\n",
      "Epoch 9/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3195 - accuracy: 0.8431 - val_loss: 0.3280 - val_accuracy: 0.8413\n",
      "Epoch 10/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3192 - accuracy: 0.8447 - val_loss: 0.3317 - val_accuracy: 0.8350\n",
      "Epoch 11/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3193 - accuracy: 0.8448 - val_loss: 0.3300 - val_accuracy: 0.8359\n",
      "Epoch 12/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3188 - accuracy: 0.8443 - val_loss: 0.3308 - val_accuracy: 0.8331\n",
      "Epoch 13/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3190 - accuracy: 0.8447 - val_loss: 0.3303 - val_accuracy: 0.8357\n",
      "Epoch 14/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3190 - accuracy: 0.8439 - val_loss: 0.3286 - val_accuracy: 0.8422\n",
      "Epoch 15/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3186 - accuracy: 0.8455 - val_loss: 0.3289 - val_accuracy: 0.8423\n",
      "Epoch 16/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3194 - accuracy: 0.8448 - val_loss: 0.3273 - val_accuracy: 0.8382\n",
      "Epoch 17/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3187 - accuracy: 0.8450 - val_loss: 0.3280 - val_accuracy: 0.8395\n",
      "Epoch 18/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3195 - accuracy: 0.8435 - val_loss: 0.3257 - val_accuracy: 0.8432\n",
      "Epoch 19/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3185 - accuracy: 0.8452 - val_loss: 0.3258 - val_accuracy: 0.8411\n",
      "Epoch 20/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8454 - val_loss: 0.3394 - val_accuracy: 0.8320\n",
      "Epoch 21/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3194 - accuracy: 0.8459 - val_loss: 0.3244 - val_accuracy: 0.8404\n",
      "Epoch 22/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3186 - accuracy: 0.8454 - val_loss: 0.3279 - val_accuracy: 0.8423\n",
      "Epoch 23/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3187 - accuracy: 0.8454 - val_loss: 0.3328 - val_accuracy: 0.8370\n",
      "Epoch 24/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8461 - val_loss: 0.3266 - val_accuracy: 0.8365\n",
      "Epoch 25/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3189 - accuracy: 0.8440 - val_loss: 0.3284 - val_accuracy: 0.8386\n",
      "Epoch 26/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3183 - accuracy: 0.8465 - val_loss: 0.3294 - val_accuracy: 0.8404\n",
      "Epoch 27/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3185 - accuracy: 0.8467 - val_loss: 0.3346 - val_accuracy: 0.8227\n",
      "Epoch 28/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3187 - accuracy: 0.8448 - val_loss: 0.3282 - val_accuracy: 0.8411\n",
      "Epoch 29/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3184 - accuracy: 0.8472 - val_loss: 0.3263 - val_accuracy: 0.8393\n",
      "Epoch 30/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8466 - val_loss: 0.3278 - val_accuracy: 0.8438\n",
      "Epoch 31/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8459 - val_loss: 0.3330 - val_accuracy: 0.8389\n",
      "Epoch 32/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8445 - val_loss: 0.3243 - val_accuracy: 0.8425\n",
      "Epoch 33/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3185 - accuracy: 0.8450 - val_loss: 0.3277 - val_accuracy: 0.8329\n",
      "Epoch 34/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8447 - val_loss: 0.3268 - val_accuracy: 0.8423\n",
      "Epoch 35/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3179 - accuracy: 0.8437 - val_loss: 0.3300 - val_accuracy: 0.8370\n",
      "Epoch 36/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3179 - accuracy: 0.8463 - val_loss: 0.3274 - val_accuracy: 0.8366\n",
      "Epoch 37/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3174 - accuracy: 0.8460 - val_loss: 0.3300 - val_accuracy: 0.8350\n",
      "Epoch 38/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3179 - accuracy: 0.8474 - val_loss: 0.3286 - val_accuracy: 0.8336\n",
      "Epoch 39/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3181 - accuracy: 0.8463 - val_loss: 0.3272 - val_accuracy: 0.8341\n",
      "Epoch 40/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3180 - accuracy: 0.8463 - val_loss: 0.3274 - val_accuracy: 0.8400\n",
      "Epoch 41/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3178 - accuracy: 0.8438 - val_loss: 0.3276 - val_accuracy: 0.8402\n",
      "Epoch 42/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3174 - accuracy: 0.8439 - val_loss: 0.3290 - val_accuracy: 0.8388\n",
      "Epoch 43/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8445 - val_loss: 0.3271 - val_accuracy: 0.8429\n",
      "Epoch 44/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8454 - val_loss: 0.3262 - val_accuracy: 0.8372\n",
      "Epoch 45/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8471 - val_loss: 0.3278 - val_accuracy: 0.8359\n",
      "Epoch 46/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8470 - val_loss: 0.3321 - val_accuracy: 0.8372\n",
      "Epoch 47/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3172 - accuracy: 0.8437 - val_loss: 0.3306 - val_accuracy: 0.8368\n",
      "Epoch 48/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3170 - accuracy: 0.8477 - val_loss: 0.3278 - val_accuracy: 0.8414\n",
      "Epoch 49/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3175 - accuracy: 0.8466 - val_loss: 0.3245 - val_accuracy: 0.8402\n",
      "Epoch 50/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3176 - accuracy: 0.8463 - val_loss: 0.3264 - val_accuracy: 0.8377\n",
      "Epoch 51/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3178 - accuracy: 0.8459 - val_loss: 0.3244 - val_accuracy: 0.8379\n",
      "Epoch 52/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8472 - val_loss: 0.3239 - val_accuracy: 0.8397\n",
      "Epoch 53/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3164 - accuracy: 0.8472 - val_loss: 0.3265 - val_accuracy: 0.8368\n",
      "Epoch 54/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8470 - val_loss: 0.3281 - val_accuracy: 0.8357\n",
      "Epoch 55/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3167 - accuracy: 0.8461 - val_loss: 0.3374 - val_accuracy: 0.8245\n",
      "Epoch 56/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3170 - accuracy: 0.8481 - val_loss: 0.3281 - val_accuracy: 0.8384\n",
      "Epoch 57/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8489 - val_loss: 0.3285 - val_accuracy: 0.8350\n",
      "Epoch 58/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3160 - accuracy: 0.8486 - val_loss: 0.3302 - val_accuracy: 0.8347\n",
      "Epoch 59/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8483 - val_loss: 0.3248 - val_accuracy: 0.8407\n",
      "Epoch 60/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3158 - accuracy: 0.8466 - val_loss: 0.3253 - val_accuracy: 0.8382\n",
      "Epoch 61/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3150 - accuracy: 0.8494 - val_loss: 0.3270 - val_accuracy: 0.8368\n",
      "Epoch 62/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8477 - val_loss: 0.3237 - val_accuracy: 0.8430\n",
      "Epoch 63/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3152 - accuracy: 0.8479 - val_loss: 0.3308 - val_accuracy: 0.8397\n",
      "Epoch 64/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3156 - accuracy: 0.8489 - val_loss: 0.3209 - val_accuracy: 0.8429\n",
      "Epoch 65/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3143 - accuracy: 0.8487 - val_loss: 0.3289 - val_accuracy: 0.8332\n",
      "Epoch 66/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3150 - accuracy: 0.8491 - val_loss: 0.3308 - val_accuracy: 0.8397\n",
      "Epoch 67/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3147 - accuracy: 0.8494 - val_loss: 0.3221 - val_accuracy: 0.8432\n",
      "Epoch 68/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3141 - accuracy: 0.8498 - val_loss: 0.3248 - val_accuracy: 0.8402\n",
      "Epoch 69/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8488 - val_loss: 0.3305 - val_accuracy: 0.8373\n",
      "Epoch 70/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3140 - accuracy: 0.8490 - val_loss: 0.3258 - val_accuracy: 0.8366\n",
      "Epoch 71/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3142 - accuracy: 0.8486 - val_loss: 0.3264 - val_accuracy: 0.8461\n",
      "Epoch 72/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3144 - accuracy: 0.8513 - val_loss: 0.3293 - val_accuracy: 0.8350\n",
      "Epoch 73/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3140 - accuracy: 0.8504 - val_loss: 0.3233 - val_accuracy: 0.8429\n",
      "Epoch 74/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3142 - accuracy: 0.8488 - val_loss: 0.3270 - val_accuracy: 0.8375\n",
      "Epoch 75/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3141 - accuracy: 0.8490 - val_loss: 0.3300 - val_accuracy: 0.8299\n",
      "Epoch 76/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8491 - val_loss: 0.3212 - val_accuracy: 0.8418\n",
      "Epoch 77/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3133 - accuracy: 0.8486 - val_loss: 0.3267 - val_accuracy: 0.8359\n",
      "Epoch 78/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3140 - accuracy: 0.8485 - val_loss: 0.3215 - val_accuracy: 0.8404\n",
      "Epoch 79/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3137 - accuracy: 0.8491 - val_loss: 0.3235 - val_accuracy: 0.8405\n",
      "Epoch 80/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8493 - val_loss: 0.3189 - val_accuracy: 0.8464\n",
      "Epoch 81/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3135 - accuracy: 0.8485 - val_loss: 0.3230 - val_accuracy: 0.8429\n",
      "Epoch 82/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3136 - accuracy: 0.8490 - val_loss: 0.3220 - val_accuracy: 0.8420\n",
      "Epoch 83/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8495 - val_loss: 0.3207 - val_accuracy: 0.8439\n",
      "Epoch 84/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3130 - accuracy: 0.8511 - val_loss: 0.3212 - val_accuracy: 0.8452\n",
      "Epoch 85/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3132 - accuracy: 0.8495 - val_loss: 0.3207 - val_accuracy: 0.8409\n",
      "Epoch 86/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8498 - val_loss: 0.3336 - val_accuracy: 0.8361\n",
      "Epoch 87/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8507 - val_loss: 0.3253 - val_accuracy: 0.8414\n",
      "Epoch 88/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8501 - val_loss: 0.3276 - val_accuracy: 0.8479\n",
      "Epoch 89/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8517 - val_loss: 0.3221 - val_accuracy: 0.8434\n",
      "Epoch 90/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3130 - accuracy: 0.8506 - val_loss: 0.3204 - val_accuracy: 0.8441\n",
      "Epoch 91/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3126 - accuracy: 0.8507 - val_loss: 0.3211 - val_accuracy: 0.8418\n",
      "Epoch 92/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8496 - val_loss: 0.3211 - val_accuracy: 0.8414\n",
      "Epoch 93/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8520 - val_loss: 0.3247 - val_accuracy: 0.8368\n",
      "Epoch 94/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3129 - accuracy: 0.8514 - val_loss: 0.3214 - val_accuracy: 0.8427\n",
      "Epoch 95/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8498 - val_loss: 0.3231 - val_accuracy: 0.8418\n",
      "Epoch 96/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.8497 - val_loss: 0.3220 - val_accuracy: 0.8413\n",
      "Epoch 97/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8502 - val_loss: 0.3231 - val_accuracy: 0.8389\n",
      "Epoch 98/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3124 - accuracy: 0.8491 - val_loss: 0.3227 - val_accuracy: 0.8413\n",
      "Epoch 99/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3117 - accuracy: 0.8511 - val_loss: 0.3299 - val_accuracy: 0.8290\n",
      "Epoch 100/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3124 - accuracy: 0.8505 - val_loss: 0.3308 - val_accuracy: 0.8284\n",
      "Epoch 101/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8494 - val_loss: 0.3254 - val_accuracy: 0.8357\n",
      "Epoch 102/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3120 - accuracy: 0.8520 - val_loss: 0.3191 - val_accuracy: 0.8443\n",
      "Epoch 103/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3122 - accuracy: 0.8501 - val_loss: 0.3209 - val_accuracy: 0.8427\n",
      "Epoch 104/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3118 - accuracy: 0.8510 - val_loss: 0.3257 - val_accuracy: 0.8340\n",
      "Epoch 105/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8487 - val_loss: 0.3184 - val_accuracy: 0.8443\n",
      "Epoch 106/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8501 - val_loss: 0.3197 - val_accuracy: 0.8414\n",
      "Epoch 107/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3122 - accuracy: 0.8517 - val_loss: 0.3208 - val_accuracy: 0.8427\n",
      "Epoch 108/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3119 - accuracy: 0.8501 - val_loss: 0.3196 - val_accuracy: 0.8420\n",
      "Epoch 109/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3119 - accuracy: 0.8506 - val_loss: 0.3259 - val_accuracy: 0.8384\n",
      "Epoch 110/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3115 - accuracy: 0.8523 - val_loss: 0.3288 - val_accuracy: 0.8338\n",
      "Epoch 111/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3114 - accuracy: 0.8515 - val_loss: 0.3227 - val_accuracy: 0.8389\n",
      "Epoch 112/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3116 - accuracy: 0.8513 - val_loss: 0.3222 - val_accuracy: 0.8405\n",
      "Epoch 113/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3115 - accuracy: 0.8506 - val_loss: 0.3200 - val_accuracy: 0.8413\n",
      "Epoch 114/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.8517 - val_loss: 0.3205 - val_accuracy: 0.8434\n",
      "Epoch 115/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3116 - accuracy: 0.8504 - val_loss: 0.3231 - val_accuracy: 0.8377\n",
      "Epoch 116/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8510 - val_loss: 0.3205 - val_accuracy: 0.8407\n",
      "Epoch 117/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3112 - accuracy: 0.8507 - val_loss: 0.3263 - val_accuracy: 0.8450\n",
      "Epoch 118/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.8522 - val_loss: 0.3208 - val_accuracy: 0.8404\n",
      "Epoch 119/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8505 - val_loss: 0.3269 - val_accuracy: 0.8434\n",
      "Epoch 120/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8523 - val_loss: 0.3252 - val_accuracy: 0.8413\n",
      "Epoch 121/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8513 - val_loss: 0.3197 - val_accuracy: 0.8438\n",
      "Epoch 122/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3110 - accuracy: 0.8512 - val_loss: 0.3189 - val_accuracy: 0.8425\n",
      "Epoch 123/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8515 - val_loss: 0.3208 - val_accuracy: 0.8441\n",
      "Epoch 124/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3105 - accuracy: 0.8518 - val_loss: 0.3275 - val_accuracy: 0.8368\n",
      "Epoch 125/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8506 - val_loss: 0.3190 - val_accuracy: 0.8420\n",
      "Epoch 126/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8512 - val_loss: 0.3261 - val_accuracy: 0.8368\n",
      "Epoch 127/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3111 - accuracy: 0.8526 - val_loss: 0.3222 - val_accuracy: 0.8375\n",
      "Epoch 128/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3112 - accuracy: 0.8515 - val_loss: 0.3201 - val_accuracy: 0.8422\n",
      "Epoch 129/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3106 - accuracy: 0.8520 - val_loss: 0.3180 - val_accuracy: 0.8427\n",
      "Epoch 130/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8523 - val_loss: 0.3178 - val_accuracy: 0.8423\n",
      "Epoch 131/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8513 - val_loss: 0.3239 - val_accuracy: 0.8434\n",
      "Epoch 132/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8533 - val_loss: 0.3207 - val_accuracy: 0.8413\n",
      "Epoch 133/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8502 - val_loss: 0.3208 - val_accuracy: 0.8363\n",
      "Epoch 134/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3107 - accuracy: 0.8534 - val_loss: 0.3188 - val_accuracy: 0.8441\n",
      "Epoch 135/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3105 - accuracy: 0.8513 - val_loss: 0.3226 - val_accuracy: 0.8441\n",
      "Epoch 136/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3103 - accuracy: 0.8523 - val_loss: 0.3179 - val_accuracy: 0.8468\n",
      "Epoch 137/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8530 - val_loss: 0.3228 - val_accuracy: 0.8425\n",
      "Epoch 138/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8523 - val_loss: 0.3184 - val_accuracy: 0.8427\n",
      "Epoch 139/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8520 - val_loss: 0.3190 - val_accuracy: 0.8416\n",
      "Epoch 140/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8527 - val_loss: 0.3207 - val_accuracy: 0.8397\n",
      "Epoch 141/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3104 - accuracy: 0.8516 - val_loss: 0.3181 - val_accuracy: 0.8434\n",
      "Epoch 142/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.8523 - val_loss: 0.3212 - val_accuracy: 0.8443\n",
      "Epoch 143/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3093 - accuracy: 0.8533 - val_loss: 0.3289 - val_accuracy: 0.8286\n",
      "Epoch 144/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3098 - accuracy: 0.8527 - val_loss: 0.3229 - val_accuracy: 0.8445\n",
      "Epoch 145/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3098 - accuracy: 0.8522 - val_loss: 0.3223 - val_accuracy: 0.8354\n",
      "Epoch 146/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3095 - accuracy: 0.8535 - val_loss: 0.3202 - val_accuracy: 0.8439\n",
      "Epoch 147/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3099 - accuracy: 0.8514 - val_loss: 0.3188 - val_accuracy: 0.8423\n",
      "Epoch 148/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3100 - accuracy: 0.8507 - val_loss: 0.3180 - val_accuracy: 0.8427\n",
      "Epoch 149/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3093 - accuracy: 0.8525 - val_loss: 0.3272 - val_accuracy: 0.8393\n",
      "Epoch 150/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3097 - accuracy: 0.8514 - val_loss: 0.3204 - val_accuracy: 0.8432\n",
      "Epoch 151/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8541 - val_loss: 0.3185 - val_accuracy: 0.8432\n",
      "Epoch 152/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3101 - accuracy: 0.8507 - val_loss: 0.3189 - val_accuracy: 0.8455\n",
      "Epoch 153/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8526 - val_loss: 0.3164 - val_accuracy: 0.8446\n",
      "Epoch 154/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3089 - accuracy: 0.8522 - val_loss: 0.3171 - val_accuracy: 0.8454\n",
      "Epoch 155/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8536 - val_loss: 0.3163 - val_accuracy: 0.8470\n",
      "Epoch 156/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8534 - val_loss: 0.3193 - val_accuracy: 0.8438\n",
      "Epoch 157/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8514 - val_loss: 0.3168 - val_accuracy: 0.8450\n",
      "Epoch 158/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8543 - val_loss: 0.3209 - val_accuracy: 0.8459\n",
      "Epoch 159/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3095 - accuracy: 0.8513 - val_loss: 0.3205 - val_accuracy: 0.8397\n",
      "Epoch 160/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8525 - val_loss: 0.3191 - val_accuracy: 0.8459\n",
      "Epoch 161/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8533 - val_loss: 0.3193 - val_accuracy: 0.8430\n",
      "Epoch 162/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3092 - accuracy: 0.8535 - val_loss: 0.3248 - val_accuracy: 0.8363\n",
      "Epoch 163/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3094 - accuracy: 0.8532 - val_loss: 0.3161 - val_accuracy: 0.8462\n",
      "Epoch 164/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3087 - accuracy: 0.8537 - val_loss: 0.3192 - val_accuracy: 0.8450\n",
      "Epoch 165/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.8539 - val_loss: 0.3224 - val_accuracy: 0.8361\n",
      "Epoch 166/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8532 - val_loss: 0.3172 - val_accuracy: 0.8473\n",
      "Epoch 167/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8549 - val_loss: 0.3170 - val_accuracy: 0.8471\n",
      "Epoch 168/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8537 - val_loss: 0.3239 - val_accuracy: 0.8411\n",
      "Epoch 169/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8530 - val_loss: 0.3216 - val_accuracy: 0.8429\n",
      "Epoch 170/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3088 - accuracy: 0.8535 - val_loss: 0.3228 - val_accuracy: 0.8370\n",
      "Epoch 171/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8548 - val_loss: 0.3186 - val_accuracy: 0.8475\n",
      "Epoch 172/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3083 - accuracy: 0.8539 - val_loss: 0.3159 - val_accuracy: 0.8430\n",
      "Epoch 173/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8543 - val_loss: 0.3189 - val_accuracy: 0.8422\n",
      "Epoch 174/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3086 - accuracy: 0.8545 - val_loss: 0.3228 - val_accuracy: 0.8420\n",
      "Epoch 175/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3085 - accuracy: 0.8555 - val_loss: 0.3156 - val_accuracy: 0.8445\n",
      "Epoch 176/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8544 - val_loss: 0.3203 - val_accuracy: 0.8420\n",
      "Epoch 177/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3079 - accuracy: 0.8543 - val_loss: 0.3163 - val_accuracy: 0.8475\n",
      "Epoch 178/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3071 - accuracy: 0.8542 - val_loss: 0.3149 - val_accuracy: 0.8477\n",
      "Epoch 179/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3074 - accuracy: 0.8547 - val_loss: 0.3238 - val_accuracy: 0.8427\n",
      "Epoch 180/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3076 - accuracy: 0.8546 - val_loss: 0.3157 - val_accuracy: 0.8439\n",
      "Epoch 181/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3073 - accuracy: 0.8547 - val_loss: 0.3221 - val_accuracy: 0.8445\n",
      "Epoch 182/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3073 - accuracy: 0.8553 - val_loss: 0.3175 - val_accuracy: 0.8489\n",
      "Epoch 183/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3072 - accuracy: 0.8535 - val_loss: 0.3174 - val_accuracy: 0.8434\n",
      "Epoch 184/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3071 - accuracy: 0.8536 - val_loss: 0.3208 - val_accuracy: 0.8462\n",
      "Epoch 185/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3072 - accuracy: 0.8544 - val_loss: 0.3156 - val_accuracy: 0.8464\n",
      "Epoch 186/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3072 - accuracy: 0.8548 - val_loss: 0.3135 - val_accuracy: 0.8514\n",
      "Epoch 187/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3067 - accuracy: 0.8554 - val_loss: 0.3157 - val_accuracy: 0.8464\n",
      "Epoch 188/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3066 - accuracy: 0.8554 - val_loss: 0.3191 - val_accuracy: 0.8402\n",
      "Epoch 189/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3068 - accuracy: 0.8549 - val_loss: 0.3172 - val_accuracy: 0.8470\n",
      "Epoch 190/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8546 - val_loss: 0.3206 - val_accuracy: 0.8427\n",
      "Epoch 191/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8554 - val_loss: 0.3224 - val_accuracy: 0.8434\n",
      "Epoch 192/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3057 - accuracy: 0.8538 - val_loss: 0.3189 - val_accuracy: 0.8455\n",
      "Epoch 193/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8541 - val_loss: 0.3171 - val_accuracy: 0.8445\n",
      "Epoch 194/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3068 - accuracy: 0.8564 - val_loss: 0.3131 - val_accuracy: 0.8461\n",
      "Epoch 195/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8560 - val_loss: 0.3191 - val_accuracy: 0.8388\n",
      "Epoch 196/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8556 - val_loss: 0.3143 - val_accuracy: 0.8484\n",
      "Epoch 197/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3065 - accuracy: 0.8561 - val_loss: 0.3138 - val_accuracy: 0.8479\n",
      "Epoch 198/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3067 - accuracy: 0.8556 - val_loss: 0.3205 - val_accuracy: 0.8420\n",
      "Epoch 199/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3062 - accuracy: 0.8543 - val_loss: 0.3180 - val_accuracy: 0.8430\n",
      "Epoch 200/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3061 - accuracy: 0.8551 - val_loss: 0.3154 - val_accuracy: 0.8443\n",
      "Epoch 201/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3065 - accuracy: 0.8545 - val_loss: 0.3157 - val_accuracy: 0.8430\n",
      "Epoch 202/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8553 - val_loss: 0.3139 - val_accuracy: 0.8473\n",
      "Epoch 203/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3060 - accuracy: 0.8548 - val_loss: 0.3123 - val_accuracy: 0.8470\n",
      "Epoch 204/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8548 - val_loss: 0.3152 - val_accuracy: 0.8443\n",
      "Epoch 205/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3059 - accuracy: 0.8554 - val_loss: 0.3155 - val_accuracy: 0.8461\n",
      "Epoch 206/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.8558 - val_loss: 0.3150 - val_accuracy: 0.8486\n",
      "Epoch 207/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8550 - val_loss: 0.3132 - val_accuracy: 0.8468\n",
      "Epoch 208/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3059 - accuracy: 0.8568 - val_loss: 0.3150 - val_accuracy: 0.8471\n",
      "Epoch 209/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3054 - accuracy: 0.8561 - val_loss: 0.3169 - val_accuracy: 0.8445\n",
      "Epoch 210/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3054 - accuracy: 0.8564 - val_loss: 0.3159 - val_accuracy: 0.8471\n",
      "Epoch 211/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8541 - val_loss: 0.3145 - val_accuracy: 0.8459\n",
      "Epoch 212/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3051 - accuracy: 0.8553 - val_loss: 0.3185 - val_accuracy: 0.8470\n",
      "Epoch 213/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3055 - accuracy: 0.8567 - val_loss: 0.3180 - val_accuracy: 0.8448\n",
      "Epoch 214/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3052 - accuracy: 0.8571 - val_loss: 0.3193 - val_accuracy: 0.8454\n",
      "Epoch 215/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3055 - accuracy: 0.8568 - val_loss: 0.3143 - val_accuracy: 0.8505\n",
      "Epoch 216/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3054 - accuracy: 0.8561 - val_loss: 0.3173 - val_accuracy: 0.8484\n",
      "Epoch 217/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3052 - accuracy: 0.8563 - val_loss: 0.3149 - val_accuracy: 0.8466\n",
      "Epoch 218/400\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.3056 - accuracy: 0.8566 - val_loss: 0.3150 - val_accuracy: 0.8511\n",
      "Epoch 219/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3052 - accuracy: 0.8576 - val_loss: 0.3160 - val_accuracy: 0.8479\n",
      "Epoch 220/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3047 - accuracy: 0.8556 - val_loss: 0.3194 - val_accuracy: 0.8473\n",
      "Epoch 221/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3054 - accuracy: 0.8557 - val_loss: 0.3145 - val_accuracy: 0.8498\n",
      "Epoch 222/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3048 - accuracy: 0.8545 - val_loss: 0.3118 - val_accuracy: 0.8475\n",
      "Epoch 223/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3046 - accuracy: 0.8572 - val_loss: 0.3176 - val_accuracy: 0.8430\n",
      "Epoch 224/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3045 - accuracy: 0.8578 - val_loss: 0.3229 - val_accuracy: 0.8423\n",
      "Epoch 225/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.8559 - val_loss: 0.3204 - val_accuracy: 0.8443\n",
      "Epoch 226/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3046 - accuracy: 0.8580 - val_loss: 0.3187 - val_accuracy: 0.8441\n",
      "Epoch 227/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3049 - accuracy: 0.8573 - val_loss: 0.3196 - val_accuracy: 0.8475\n",
      "Epoch 228/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8567 - val_loss: 0.3184 - val_accuracy: 0.8448\n",
      "Epoch 229/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3045 - accuracy: 0.8556 - val_loss: 0.3136 - val_accuracy: 0.8439\n",
      "Epoch 230/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3039 - accuracy: 0.8577 - val_loss: 0.3153 - val_accuracy: 0.8439\n",
      "Epoch 231/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8574 - val_loss: 0.3198 - val_accuracy: 0.8441\n",
      "Epoch 232/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3035 - accuracy: 0.8570 - val_loss: 0.3123 - val_accuracy: 0.8527\n",
      "Epoch 233/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3026 - accuracy: 0.8598 - val_loss: 0.3179 - val_accuracy: 0.8450\n",
      "Epoch 234/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8580 - val_loss: 0.3141 - val_accuracy: 0.8496\n",
      "Epoch 235/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.8585 - val_loss: 0.3165 - val_accuracy: 0.8446\n",
      "Epoch 236/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3032 - accuracy: 0.8584 - val_loss: 0.3200 - val_accuracy: 0.8470\n",
      "Epoch 237/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3023 - accuracy: 0.8586 - val_loss: 0.3205 - val_accuracy: 0.8464\n",
      "Epoch 238/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3034 - accuracy: 0.8604 - val_loss: 0.3169 - val_accuracy: 0.8416\n",
      "Epoch 239/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3034 - accuracy: 0.8597 - val_loss: 0.3106 - val_accuracy: 0.8475\n",
      "Epoch 240/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3027 - accuracy: 0.8589 - val_loss: 0.3112 - val_accuracy: 0.8475\n",
      "Epoch 241/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3020 - accuracy: 0.8580 - val_loss: 0.3110 - val_accuracy: 0.8505\n",
      "Epoch 242/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3028 - accuracy: 0.8585 - val_loss: 0.3153 - val_accuracy: 0.8450\n",
      "Epoch 243/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3027 - accuracy: 0.8588 - val_loss: 0.3098 - val_accuracy: 0.8536\n",
      "Epoch 244/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3030 - accuracy: 0.8583 - val_loss: 0.3115 - val_accuracy: 0.8489\n",
      "Epoch 245/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3025 - accuracy: 0.8583 - val_loss: 0.3151 - val_accuracy: 0.8468\n",
      "Epoch 246/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3021 - accuracy: 0.8577 - val_loss: 0.3195 - val_accuracy: 0.8496\n",
      "Epoch 247/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3024 - accuracy: 0.8587 - val_loss: 0.3136 - val_accuracy: 0.8495\n",
      "Epoch 248/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3018 - accuracy: 0.8576 - val_loss: 0.3126 - val_accuracy: 0.8512\n",
      "Epoch 249/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.8587 - val_loss: 0.3082 - val_accuracy: 0.8530\n",
      "Epoch 250/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3028 - accuracy: 0.8591 - val_loss: 0.3103 - val_accuracy: 0.8495\n",
      "Epoch 251/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3020 - accuracy: 0.8587 - val_loss: 0.3110 - val_accuracy: 0.8511\n",
      "Epoch 252/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.8580 - val_loss: 0.3128 - val_accuracy: 0.8498\n",
      "Epoch 253/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.8602 - val_loss: 0.3182 - val_accuracy: 0.8477\n",
      "Epoch 254/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.8591 - val_loss: 0.3093 - val_accuracy: 0.8518\n",
      "Epoch 255/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3024 - accuracy: 0.8579 - val_loss: 0.3176 - val_accuracy: 0.8500\n",
      "Epoch 256/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3016 - accuracy: 0.8590 - val_loss: 0.3185 - val_accuracy: 0.8461\n",
      "Epoch 257/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3025 - accuracy: 0.8580 - val_loss: 0.3097 - val_accuracy: 0.8527\n",
      "Epoch 258/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3017 - accuracy: 0.8577 - val_loss: 0.3203 - val_accuracy: 0.8457\n",
      "Epoch 259/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.8584 - val_loss: 0.3177 - val_accuracy: 0.8480\n",
      "Epoch 260/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3023 - accuracy: 0.8592 - val_loss: 0.3090 - val_accuracy: 0.8505\n",
      "Epoch 261/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3019 - accuracy: 0.8601 - val_loss: 0.3115 - val_accuracy: 0.8507\n",
      "Epoch 262/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3014 - accuracy: 0.8586 - val_loss: 0.3084 - val_accuracy: 0.8520\n",
      "Epoch 263/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3018 - accuracy: 0.8594 - val_loss: 0.3095 - val_accuracy: 0.8525\n",
      "Epoch 264/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8588 - val_loss: 0.3184 - val_accuracy: 0.8414\n",
      "Epoch 265/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3016 - accuracy: 0.8597 - val_loss: 0.3137 - val_accuracy: 0.8493\n",
      "Epoch 266/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3015 - accuracy: 0.8596 - val_loss: 0.3081 - val_accuracy: 0.8493\n",
      "Epoch 267/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8584 - val_loss: 0.3165 - val_accuracy: 0.8429\n",
      "Epoch 268/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8596 - val_loss: 0.3081 - val_accuracy: 0.8498\n",
      "Epoch 269/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3011 - accuracy: 0.8589 - val_loss: 0.3109 - val_accuracy: 0.8464\n",
      "Epoch 270/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8601 - val_loss: 0.3096 - val_accuracy: 0.8516\n",
      "Epoch 271/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8599 - val_loss: 0.3300 - val_accuracy: 0.8315\n",
      "Epoch 272/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8576 - val_loss: 0.3109 - val_accuracy: 0.8496\n",
      "Epoch 273/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8591 - val_loss: 0.3096 - val_accuracy: 0.8530\n",
      "Epoch 274/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3013 - accuracy: 0.8599 - val_loss: 0.3140 - val_accuracy: 0.8448\n",
      "Epoch 275/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3010 - accuracy: 0.8599 - val_loss: 0.3120 - val_accuracy: 0.8496\n",
      "Epoch 276/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3012 - accuracy: 0.8590 - val_loss: 0.3100 - val_accuracy: 0.8489\n",
      "Epoch 277/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3011 - accuracy: 0.8605 - val_loss: 0.3102 - val_accuracy: 0.8498\n",
      "Epoch 278/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3013 - accuracy: 0.8596 - val_loss: 0.3133 - val_accuracy: 0.8471\n",
      "Epoch 279/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3015 - accuracy: 0.8591 - val_loss: 0.3076 - val_accuracy: 0.8514\n",
      "Epoch 280/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3003 - accuracy: 0.8617 - val_loss: 0.3124 - val_accuracy: 0.8503\n",
      "Epoch 281/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.2999 - accuracy: 0.8594 - val_loss: 0.3167 - val_accuracy: 0.8450\n",
      "Epoch 282/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8608 - val_loss: 0.3170 - val_accuracy: 0.8470\n",
      "Epoch 283/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8602 - val_loss: 0.3112 - val_accuracy: 0.8493\n",
      "Epoch 284/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3012 - accuracy: 0.8576 - val_loss: 0.3174 - val_accuracy: 0.8509\n",
      "Epoch 285/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.8595 - val_loss: 0.3140 - val_accuracy: 0.8457\n",
      "Epoch 286/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.8584 - val_loss: 0.3064 - val_accuracy: 0.8528\n",
      "Epoch 287/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3003 - accuracy: 0.8601 - val_loss: 0.3076 - val_accuracy: 0.8528\n",
      "Epoch 288/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3006 - accuracy: 0.8594 - val_loss: 0.3141 - val_accuracy: 0.8468\n",
      "Epoch 289/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3000 - accuracy: 0.8610 - val_loss: 0.3143 - val_accuracy: 0.8480\n",
      "Epoch 290/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3008 - accuracy: 0.8605 - val_loss: 0.3151 - val_accuracy: 0.8466\n",
      "Epoch 291/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8596 - val_loss: 0.3226 - val_accuracy: 0.8470\n",
      "Epoch 292/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8596 - val_loss: 0.3137 - val_accuracy: 0.8500\n",
      "Epoch 293/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3004 - accuracy: 0.8605 - val_loss: 0.3277 - val_accuracy: 0.8359\n",
      "Epoch 294/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.8598 - val_loss: 0.3109 - val_accuracy: 0.8480\n",
      "Epoch 295/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.8592 - val_loss: 0.3128 - val_accuracy: 0.8473\n",
      "Epoch 296/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3009 - accuracy: 0.8604 - val_loss: 0.3147 - val_accuracy: 0.8475\n",
      "Epoch 297/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.8601 - val_loss: 0.3170 - val_accuracy: 0.8507\n",
      "Epoch 298/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8603 - val_loss: 0.3081 - val_accuracy: 0.8516\n",
      "Epoch 299/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8608 - val_loss: 0.3104 - val_accuracy: 0.8516\n",
      "Epoch 300/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3002 - accuracy: 0.8599 - val_loss: 0.3089 - val_accuracy: 0.8518\n",
      "Epoch 301/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3002 - accuracy: 0.8613 - val_loss: 0.3092 - val_accuracy: 0.8527\n",
      "Epoch 302/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8585 - val_loss: 0.3082 - val_accuracy: 0.8487\n",
      "Epoch 303/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3005 - accuracy: 0.8594 - val_loss: 0.3131 - val_accuracy: 0.8507\n",
      "Epoch 304/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8610 - val_loss: 0.3187 - val_accuracy: 0.8454\n",
      "Epoch 305/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3003 - accuracy: 0.8614 - val_loss: 0.3109 - val_accuracy: 0.8491\n",
      "Epoch 306/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3004 - accuracy: 0.8601 - val_loss: 0.3124 - val_accuracy: 0.8498\n",
      "Epoch 307/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3003 - accuracy: 0.8609 - val_loss: 0.3135 - val_accuracy: 0.8521\n",
      "Epoch 308/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3001 - accuracy: 0.8596 - val_loss: 0.3102 - val_accuracy: 0.8521\n",
      "Epoch 309/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.2999 - accuracy: 0.8610 - val_loss: 0.3113 - val_accuracy: 0.8509\n",
      "Epoch 310/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3001 - accuracy: 0.8601 - val_loss: 0.3072 - val_accuracy: 0.8509\n",
      "Epoch 311/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.2995 - accuracy: 0.8607 - val_loss: 0.3132 - val_accuracy: 0.8427\n",
      "Epoch 312/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3006 - accuracy: 0.8607 - val_loss: 0.3096 - val_accuracy: 0.8495\n",
      "Epoch 313/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.2994 - accuracy: 0.8602 - val_loss: 0.3166 - val_accuracy: 0.8466\n",
      "Epoch 314/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3004 - accuracy: 0.8588 - val_loss: 0.3073 - val_accuracy: 0.8525\n",
      "Epoch 315/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3003 - accuracy: 0.8606 - val_loss: 0.3092 - val_accuracy: 0.8507\n",
      "Epoch 316/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8597 - val_loss: 0.3117 - val_accuracy: 0.8479\n",
      "Epoch 317/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3003 - accuracy: 0.8600 - val_loss: 0.3101 - val_accuracy: 0.8520\n",
      "Epoch 318/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.2994 - accuracy: 0.8599 - val_loss: 0.3076 - val_accuracy: 0.8480\n",
      "Epoch 319/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.8611 - val_loss: 0.3091 - val_accuracy: 0.8520\n",
      "Epoch 320/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.8599 - val_loss: 0.3096 - val_accuracy: 0.8503\n",
      "Epoch 321/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2992 - accuracy: 0.8607 - val_loss: 0.3156 - val_accuracy: 0.8470\n",
      "Epoch 322/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.8616 - val_loss: 0.3095 - val_accuracy: 0.8553\n",
      "Epoch 323/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.2998 - accuracy: 0.8598 - val_loss: 0.3103 - val_accuracy: 0.8493\n",
      "Epoch 324/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8605 - val_loss: 0.3088 - val_accuracy: 0.8502\n",
      "Epoch 325/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8592 - val_loss: 0.3169 - val_accuracy: 0.8480\n",
      "Epoch 326/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8609 - val_loss: 0.3122 - val_accuracy: 0.8468\n",
      "Epoch 327/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8601 - val_loss: 0.3082 - val_accuracy: 0.8507\n",
      "Epoch 328/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.2992 - accuracy: 0.8610 - val_loss: 0.3110 - val_accuracy: 0.8509\n",
      "Epoch 329/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8610 - val_loss: 0.3107 - val_accuracy: 0.8457\n",
      "Epoch 330/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.8596 - val_loss: 0.3087 - val_accuracy: 0.8528\n",
      "Epoch 331/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8621 - val_loss: 0.3088 - val_accuracy: 0.8498\n",
      "Epoch 332/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8607 - val_loss: 0.3105 - val_accuracy: 0.8491\n",
      "Epoch 333/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.2994 - accuracy: 0.8604 - val_loss: 0.3106 - val_accuracy: 0.8537\n",
      "Epoch 334/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.2996 - accuracy: 0.8592 - val_loss: 0.3148 - val_accuracy: 0.8423\n",
      "Epoch 335/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2994 - accuracy: 0.8613 - val_loss: 0.3194 - val_accuracy: 0.8482\n",
      "Epoch 336/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8612 - val_loss: 0.3102 - val_accuracy: 0.8491\n",
      "Epoch 337/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8596 - val_loss: 0.3087 - val_accuracy: 0.8550\n",
      "Epoch 338/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8602 - val_loss: 0.3082 - val_accuracy: 0.8505\n",
      "Epoch 339/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8599 - val_loss: 0.3071 - val_accuracy: 0.8532\n",
      "Epoch 340/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.8607 - val_loss: 0.3125 - val_accuracy: 0.8520\n",
      "Epoch 341/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3000 - accuracy: 0.8615 - val_loss: 0.3051 - val_accuracy: 0.8532\n",
      "Epoch 342/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8610 - val_loss: 0.3098 - val_accuracy: 0.8475\n",
      "Epoch 343/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.8616 - val_loss: 0.3093 - val_accuracy: 0.8503\n",
      "Epoch 344/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.2994 - accuracy: 0.8608 - val_loss: 0.3070 - val_accuracy: 0.8555\n",
      "Epoch 345/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.2988 - accuracy: 0.8612 - val_loss: 0.3168 - val_accuracy: 0.8480\n",
      "Epoch 346/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.2994 - accuracy: 0.8600 - val_loss: 0.3091 - val_accuracy: 0.8537\n",
      "Epoch 347/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.2992 - accuracy: 0.8596 - val_loss: 0.3109 - val_accuracy: 0.8520\n",
      "Epoch 348/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.2989 - accuracy: 0.8608 - val_loss: 0.3093 - val_accuracy: 0.8459\n",
      "Epoch 349/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.2988 - accuracy: 0.8604 - val_loss: 0.3130 - val_accuracy: 0.8477\n",
      "Epoch 350/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.2994 - accuracy: 0.8605 - val_loss: 0.3072 - val_accuracy: 0.8539\n",
      "Epoch 351/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.8584 - val_loss: 0.3093 - val_accuracy: 0.8496\n",
      "Epoch 352/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.8601 - val_loss: 0.3125 - val_accuracy: 0.8534\n",
      "Epoch 353/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2993 - accuracy: 0.8595 - val_loss: 0.3140 - val_accuracy: 0.8512\n",
      "Epoch 354/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.8599 - val_loss: 0.3113 - val_accuracy: 0.8468\n",
      "Epoch 355/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.2989 - accuracy: 0.8616 - val_loss: 0.3091 - val_accuracy: 0.8502\n",
      "Epoch 356/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.8597 - val_loss: 0.3087 - val_accuracy: 0.8509\n",
      "Epoch 357/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8607 - val_loss: 0.3080 - val_accuracy: 0.8550\n",
      "Epoch 358/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.8607 - val_loss: 0.3061 - val_accuracy: 0.8520\n",
      "Epoch 359/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8629 - val_loss: 0.3051 - val_accuracy: 0.8514\n",
      "Epoch 360/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8600 - val_loss: 0.3109 - val_accuracy: 0.8509\n",
      "Epoch 361/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.2986 - accuracy: 0.8602 - val_loss: 0.3103 - val_accuracy: 0.8443\n",
      "Epoch 362/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.8611 - val_loss: 0.3164 - val_accuracy: 0.8480\n",
      "Epoch 363/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.8601 - val_loss: 0.3123 - val_accuracy: 0.8459\n",
      "Epoch 364/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8612 - val_loss: 0.3073 - val_accuracy: 0.8527\n",
      "Epoch 365/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2991 - accuracy: 0.8602 - val_loss: 0.3116 - val_accuracy: 0.8493\n",
      "Epoch 366/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.2992 - accuracy: 0.8607 - val_loss: 0.3060 - val_accuracy: 0.8507\n",
      "Epoch 367/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8602 - val_loss: 0.3096 - val_accuracy: 0.8512\n",
      "Epoch 368/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.2992 - accuracy: 0.8605 - val_loss: 0.3096 - val_accuracy: 0.8541\n",
      "Epoch 369/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8595 - val_loss: 0.3068 - val_accuracy: 0.8523\n",
      "Epoch 370/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8601 - val_loss: 0.3277 - val_accuracy: 0.8377\n",
      "Epoch 371/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.8589 - val_loss: 0.3118 - val_accuracy: 0.8457\n",
      "Epoch 372/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8615 - val_loss: 0.3075 - val_accuracy: 0.8537\n",
      "Epoch 373/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8602 - val_loss: 0.3157 - val_accuracy: 0.8445\n",
      "Epoch 374/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2985 - accuracy: 0.8610 - val_loss: 0.3088 - val_accuracy: 0.8502\n",
      "Epoch 375/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8598 - val_loss: 0.3113 - val_accuracy: 0.8503\n",
      "Epoch 376/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2983 - accuracy: 0.8607 - val_loss: 0.3108 - val_accuracy: 0.8521\n",
      "Epoch 377/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.2986 - accuracy: 0.8606 - val_loss: 0.3052 - val_accuracy: 0.8521\n",
      "Epoch 378/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.2989 - accuracy: 0.8597 - val_loss: 0.3062 - val_accuracy: 0.8525\n",
      "Epoch 379/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.2985 - accuracy: 0.8608 - val_loss: 0.3114 - val_accuracy: 0.8484\n",
      "Epoch 380/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.2978 - accuracy: 0.8605 - val_loss: 0.3109 - val_accuracy: 0.8446\n",
      "Epoch 381/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.2985 - accuracy: 0.8608 - val_loss: 0.3096 - val_accuracy: 0.8459\n",
      "Epoch 382/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.2991 - accuracy: 0.8586 - val_loss: 0.3246 - val_accuracy: 0.8377\n",
      "Epoch 383/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.2980 - accuracy: 0.8621 - val_loss: 0.3064 - val_accuracy: 0.8516\n",
      "Epoch 384/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.2979 - accuracy: 0.8601 - val_loss: 0.3080 - val_accuracy: 0.8498\n",
      "Epoch 385/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.2978 - accuracy: 0.8620 - val_loss: 0.3085 - val_accuracy: 0.8495\n",
      "Epoch 386/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2982 - accuracy: 0.8601 - val_loss: 0.3097 - val_accuracy: 0.8502\n",
      "Epoch 387/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.2984 - accuracy: 0.8605 - val_loss: 0.3179 - val_accuracy: 0.8462\n",
      "Epoch 388/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.8595 - val_loss: 0.3063 - val_accuracy: 0.8521\n",
      "Epoch 389/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.2979 - accuracy: 0.8617 - val_loss: 0.3145 - val_accuracy: 0.8462\n",
      "Epoch 390/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.8605 - val_loss: 0.3120 - val_accuracy: 0.8434\n",
      "Epoch 391/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.2982 - accuracy: 0.8606 - val_loss: 0.3091 - val_accuracy: 0.8537\n",
      "Epoch 392/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.2984 - accuracy: 0.8600 - val_loss: 0.3084 - val_accuracy: 0.8527\n",
      "Epoch 393/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8607 - val_loss: 0.3144 - val_accuracy: 0.8502\n",
      "Epoch 394/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.2973 - accuracy: 0.8614 - val_loss: 0.3111 - val_accuracy: 0.8477\n",
      "Epoch 395/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2980 - accuracy: 0.8607 - val_loss: 0.3067 - val_accuracy: 0.8516\n",
      "Epoch 396/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8613 - val_loss: 0.3093 - val_accuracy: 0.8543\n",
      "Epoch 397/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.2979 - accuracy: 0.8603 - val_loss: 0.3075 - val_accuracy: 0.8502\n",
      "Epoch 398/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.2977 - accuracy: 0.8612 - val_loss: 0.3056 - val_accuracy: 0.8530\n",
      "Epoch 399/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.2983 - accuracy: 0.8625 - val_loss: 0.3114 - val_accuracy: 0.8520\n",
      "Epoch 400/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.2983 - accuracy: 0.8623 - val_loss: 0.3092 - val_accuracy: 0.8507\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a1efa0688>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, validation_data=(X_test, y_test), epochs=400, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping   = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=12)\n",
    "model_checkpoint = ModelCheckpoint(monitor='val_loss', save_best_only=True, filepath=\"model_checkpoint.keras\")\n",
    "callback_list    = [early_stopping,model_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classification_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " first_layer (Dense)         (None, 20)                140       \n",
      "                                                                 \n",
      " second_layer (Dense)        (None, 8)                 168       \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 317\n",
      "Trainable params: 317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "176/176 [==============================] - 4s 14ms/step - loss: 0.6257 - accuracy: 0.6615 - val_loss: 0.5621 - val_accuracy: 0.7221\n",
      "Epoch 2/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5329 - accuracy: 0.7345 - val_loss: 0.5086 - val_accuracy: 0.7506\n",
      "Epoch 3/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.4953 - accuracy: 0.7513 - val_loss: 0.4807 - val_accuracy: 0.7595\n",
      "Epoch 4/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.4652 - accuracy: 0.7621 - val_loss: 0.4567 - val_accuracy: 0.7736\n",
      "Epoch 5/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.4481 - accuracy: 0.7732 - val_loss: 0.4443 - val_accuracy: 0.7823\n",
      "Epoch 6/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.4382 - accuracy: 0.7813 - val_loss: 0.4356 - val_accuracy: 0.7855\n",
      "Epoch 7/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.4306 - accuracy: 0.7846 - val_loss: 0.4299 - val_accuracy: 0.7894\n",
      "Epoch 8/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.4243 - accuracy: 0.7888 - val_loss: 0.4219 - val_accuracy: 0.7907\n",
      "Epoch 9/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.4188 - accuracy: 0.7910 - val_loss: 0.4180 - val_accuracy: 0.7924\n",
      "Epoch 10/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.4147 - accuracy: 0.7925 - val_loss: 0.4143 - val_accuracy: 0.7891\n",
      "Epoch 11/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.4111 - accuracy: 0.7937 - val_loss: 0.4102 - val_accuracy: 0.7960\n",
      "Epoch 12/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.4081 - accuracy: 0.7951 - val_loss: 0.4064 - val_accuracy: 0.7981\n",
      "Epoch 13/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.4054 - accuracy: 0.7966 - val_loss: 0.4036 - val_accuracy: 0.8017\n",
      "Epoch 14/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.4032 - accuracy: 0.7976 - val_loss: 0.4016 - val_accuracy: 0.8078\n",
      "Epoch 15/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.7979 - val_loss: 0.3995 - val_accuracy: 0.8031\n",
      "Epoch 16/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3983 - accuracy: 0.8001 - val_loss: 0.3962 - val_accuracy: 0.8021\n",
      "Epoch 17/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3956 - accuracy: 0.8003 - val_loss: 0.3953 - val_accuracy: 0.8008\n",
      "Epoch 18/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3935 - accuracy: 0.8014 - val_loss: 0.3923 - val_accuracy: 0.8022\n",
      "Epoch 19/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3918 - accuracy: 0.8035 - val_loss: 0.3906 - val_accuracy: 0.8055\n",
      "Epoch 20/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3899 - accuracy: 0.8051 - val_loss: 0.3891 - val_accuracy: 0.8081\n",
      "Epoch 21/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3881 - accuracy: 0.8046 - val_loss: 0.3883 - val_accuracy: 0.8062\n",
      "Epoch 22/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3867 - accuracy: 0.8045 - val_loss: 0.3854 - val_accuracy: 0.8124\n",
      "Epoch 23/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3852 - accuracy: 0.8067 - val_loss: 0.3845 - val_accuracy: 0.8115\n",
      "Epoch 24/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3838 - accuracy: 0.8059 - val_loss: 0.3849 - val_accuracy: 0.8101\n",
      "Epoch 25/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3825 - accuracy: 0.8071 - val_loss: 0.3820 - val_accuracy: 0.8119\n",
      "Epoch 26/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3816 - accuracy: 0.8086 - val_loss: 0.3816 - val_accuracy: 0.8090\n",
      "Epoch 27/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3803 - accuracy: 0.8074 - val_loss: 0.3806 - val_accuracy: 0.8117\n",
      "Epoch 28/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3794 - accuracy: 0.8080 - val_loss: 0.3789 - val_accuracy: 0.8115\n",
      "Epoch 29/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3782 - accuracy: 0.8095 - val_loss: 0.3786 - val_accuracy: 0.8106\n",
      "Epoch 30/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3771 - accuracy: 0.8098 - val_loss: 0.3779 - val_accuracy: 0.8083\n",
      "Epoch 31/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3759 - accuracy: 0.8103 - val_loss: 0.3762 - val_accuracy: 0.8108\n",
      "Epoch 32/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3749 - accuracy: 0.8090 - val_loss: 0.3745 - val_accuracy: 0.8135\n",
      "Epoch 33/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3740 - accuracy: 0.8107 - val_loss: 0.3734 - val_accuracy: 0.8133\n",
      "Epoch 34/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3734 - accuracy: 0.8109 - val_loss: 0.3734 - val_accuracy: 0.8129\n",
      "Epoch 35/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.8107 - val_loss: 0.3752 - val_accuracy: 0.8103\n",
      "Epoch 36/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3715 - accuracy: 0.8118 - val_loss: 0.3708 - val_accuracy: 0.8165\n",
      "Epoch 37/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3706 - accuracy: 0.8116 - val_loss: 0.3730 - val_accuracy: 0.8112\n",
      "Epoch 38/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3699 - accuracy: 0.8117 - val_loss: 0.3696 - val_accuracy: 0.8167\n",
      "Epoch 39/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3685 - accuracy: 0.8133 - val_loss: 0.3709 - val_accuracy: 0.8104\n",
      "Epoch 40/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3678 - accuracy: 0.8128 - val_loss: 0.3683 - val_accuracy: 0.8176\n",
      "Epoch 41/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3669 - accuracy: 0.8161 - val_loss: 0.3671 - val_accuracy: 0.8176\n",
      "Epoch 42/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3659 - accuracy: 0.8168 - val_loss: 0.3681 - val_accuracy: 0.8156\n",
      "Epoch 43/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3650 - accuracy: 0.8180 - val_loss: 0.3684 - val_accuracy: 0.8144\n",
      "Epoch 44/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3642 - accuracy: 0.8186 - val_loss: 0.3657 - val_accuracy: 0.8206\n",
      "Epoch 45/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3634 - accuracy: 0.8188 - val_loss: 0.3647 - val_accuracy: 0.8158\n",
      "Epoch 46/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3626 - accuracy: 0.8203 - val_loss: 0.3639 - val_accuracy: 0.8190\n",
      "Epoch 47/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3623 - accuracy: 0.8194 - val_loss: 0.3635 - val_accuracy: 0.8193\n",
      "Epoch 48/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3611 - accuracy: 0.8200 - val_loss: 0.3629 - val_accuracy: 0.8177\n",
      "Epoch 49/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3606 - accuracy: 0.8201 - val_loss: 0.3628 - val_accuracy: 0.8177\n",
      "Epoch 50/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3603 - accuracy: 0.8202 - val_loss: 0.3612 - val_accuracy: 0.8220\n",
      "Epoch 51/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3594 - accuracy: 0.8206 - val_loss: 0.3633 - val_accuracy: 0.8135\n",
      "Epoch 52/400\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.3585 - accuracy: 0.8220 - val_loss: 0.3597 - val_accuracy: 0.8206\n",
      "Epoch 53/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3575 - accuracy: 0.8227 - val_loss: 0.3608 - val_accuracy: 0.8154\n",
      "Epoch 54/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3567 - accuracy: 0.8232 - val_loss: 0.3583 - val_accuracy: 0.8227\n",
      "Epoch 55/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3564 - accuracy: 0.8234 - val_loss: 0.3570 - val_accuracy: 0.8279\n",
      "Epoch 56/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3559 - accuracy: 0.8242 - val_loss: 0.3560 - val_accuracy: 0.8267\n",
      "Epoch 57/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3551 - accuracy: 0.8242 - val_loss: 0.3564 - val_accuracy: 0.8243\n",
      "Epoch 58/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3546 - accuracy: 0.8242 - val_loss: 0.3558 - val_accuracy: 0.8265\n",
      "Epoch 59/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3540 - accuracy: 0.8226 - val_loss: 0.3601 - val_accuracy: 0.8206\n",
      "Epoch 60/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3537 - accuracy: 0.8244 - val_loss: 0.3549 - val_accuracy: 0.8254\n",
      "Epoch 61/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3531 - accuracy: 0.8222 - val_loss: 0.3540 - val_accuracy: 0.8247\n",
      "Epoch 62/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3529 - accuracy: 0.8237 - val_loss: 0.3534 - val_accuracy: 0.8252\n",
      "Epoch 63/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8231 - val_loss: 0.3544 - val_accuracy: 0.8249\n",
      "Epoch 64/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3514 - accuracy: 0.8234 - val_loss: 0.3567 - val_accuracy: 0.8101\n",
      "Epoch 65/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3513 - accuracy: 0.8241 - val_loss: 0.3514 - val_accuracy: 0.8275\n",
      "Epoch 66/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3509 - accuracy: 0.8254 - val_loss: 0.3586 - val_accuracy: 0.8090\n",
      "Epoch 67/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3507 - accuracy: 0.8236 - val_loss: 0.3510 - val_accuracy: 0.8247\n",
      "Epoch 68/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3502 - accuracy: 0.8254 - val_loss: 0.3498 - val_accuracy: 0.8238\n",
      "Epoch 69/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3494 - accuracy: 0.8238 - val_loss: 0.3521 - val_accuracy: 0.8274\n",
      "Epoch 70/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3489 - accuracy: 0.8247 - val_loss: 0.3489 - val_accuracy: 0.8224\n",
      "Epoch 71/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3489 - accuracy: 0.8247 - val_loss: 0.3484 - val_accuracy: 0.8302\n",
      "Epoch 72/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8248 - val_loss: 0.3514 - val_accuracy: 0.8147\n",
      "Epoch 73/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3477 - accuracy: 0.8241 - val_loss: 0.3478 - val_accuracy: 0.8313\n",
      "Epoch 74/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3475 - accuracy: 0.8249 - val_loss: 0.3504 - val_accuracy: 0.8208\n",
      "Epoch 75/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3473 - accuracy: 0.8257 - val_loss: 0.3492 - val_accuracy: 0.8261\n",
      "Epoch 76/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3468 - accuracy: 0.8261 - val_loss: 0.3476 - val_accuracy: 0.8272\n",
      "Epoch 77/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3461 - accuracy: 0.8251 - val_loss: 0.3475 - val_accuracy: 0.8247\n",
      "Epoch 78/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3463 - accuracy: 0.8266 - val_loss: 0.3463 - val_accuracy: 0.8277\n",
      "Epoch 79/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3457 - accuracy: 0.8252 - val_loss: 0.3489 - val_accuracy: 0.8172\n",
      "Epoch 80/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3454 - accuracy: 0.8252 - val_loss: 0.3483 - val_accuracy: 0.8236\n",
      "Epoch 81/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3451 - accuracy: 0.8272 - val_loss: 0.3510 - val_accuracy: 0.8145\n",
      "Epoch 82/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3450 - accuracy: 0.8256 - val_loss: 0.3452 - val_accuracy: 0.8302\n",
      "Epoch 83/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8262 - val_loss: 0.3468 - val_accuracy: 0.8234\n",
      "Epoch 84/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8258 - val_loss: 0.3488 - val_accuracy: 0.8192\n",
      "Epoch 85/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8270 - val_loss: 0.3478 - val_accuracy: 0.8254\n",
      "Epoch 86/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3439 - accuracy: 0.8266 - val_loss: 0.3441 - val_accuracy: 0.8291\n",
      "Epoch 87/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3432 - accuracy: 0.8265 - val_loss: 0.3469 - val_accuracy: 0.8227\n",
      "Epoch 88/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3433 - accuracy: 0.8259 - val_loss: 0.3455 - val_accuracy: 0.8249\n",
      "Epoch 89/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3430 - accuracy: 0.8244 - val_loss: 0.3434 - val_accuracy: 0.8299\n",
      "Epoch 90/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3422 - accuracy: 0.8257 - val_loss: 0.3458 - val_accuracy: 0.8297\n",
      "Epoch 91/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3422 - accuracy: 0.8263 - val_loss: 0.3432 - val_accuracy: 0.8247\n",
      "Epoch 92/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3423 - accuracy: 0.8263 - val_loss: 0.3451 - val_accuracy: 0.8226\n",
      "Epoch 93/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3414 - accuracy: 0.8274 - val_loss: 0.3468 - val_accuracy: 0.8252\n",
      "Epoch 94/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3415 - accuracy: 0.8255 - val_loss: 0.3423 - val_accuracy: 0.8281\n",
      "Epoch 95/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3411 - accuracy: 0.8278 - val_loss: 0.3421 - val_accuracy: 0.8267\n",
      "Epoch 96/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3409 - accuracy: 0.8257 - val_loss: 0.3426 - val_accuracy: 0.8250\n",
      "Epoch 97/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3405 - accuracy: 0.8277 - val_loss: 0.3410 - val_accuracy: 0.8299\n",
      "Epoch 98/400\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.3403 - accuracy: 0.8269 - val_loss: 0.3412 - val_accuracy: 0.8281\n",
      "Epoch 99/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3400 - accuracy: 0.8264 - val_loss: 0.3432 - val_accuracy: 0.8250\n",
      "Epoch 100/400\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.3398 - accuracy: 0.8271 - val_loss: 0.3419 - val_accuracy: 0.8304\n",
      "Epoch 101/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3388 - accuracy: 0.8277 - val_loss: 0.3492 - val_accuracy: 0.8144\n",
      "Epoch 102/400\n",
      "176/176 [==============================] - 1s 7ms/step - loss: 0.3395 - accuracy: 0.8271 - val_loss: 0.3388 - val_accuracy: 0.8311\n",
      "Epoch 103/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3388 - accuracy: 0.8277 - val_loss: 0.3399 - val_accuracy: 0.8233\n",
      "Epoch 104/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3385 - accuracy: 0.8288 - val_loss: 0.3433 - val_accuracy: 0.8188\n",
      "Epoch 105/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3386 - accuracy: 0.8273 - val_loss: 0.3420 - val_accuracy: 0.8186\n",
      "Epoch 106/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3375 - accuracy: 0.8290 - val_loss: 0.3410 - val_accuracy: 0.8208\n",
      "Epoch 107/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3372 - accuracy: 0.8288 - val_loss: 0.3374 - val_accuracy: 0.8279\n",
      "Epoch 108/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3367 - accuracy: 0.8287 - val_loss: 0.3415 - val_accuracy: 0.8199\n",
      "Epoch 109/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8288 - val_loss: 0.3367 - val_accuracy: 0.8291\n",
      "Epoch 110/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3359 - accuracy: 0.8301 - val_loss: 0.3369 - val_accuracy: 0.8318\n",
      "Epoch 111/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3355 - accuracy: 0.8321 - val_loss: 0.3362 - val_accuracy: 0.8324\n",
      "Epoch 112/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3354 - accuracy: 0.8314 - val_loss: 0.3367 - val_accuracy: 0.8261\n",
      "Epoch 113/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3351 - accuracy: 0.8307 - val_loss: 0.3428 - val_accuracy: 0.8181\n",
      "Epoch 114/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3350 - accuracy: 0.8303 - val_loss: 0.3356 - val_accuracy: 0.8356\n",
      "Epoch 115/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3345 - accuracy: 0.8325 - val_loss: 0.3351 - val_accuracy: 0.8357\n",
      "Epoch 116/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3343 - accuracy: 0.8316 - val_loss: 0.3362 - val_accuracy: 0.8397\n",
      "Epoch 117/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3334 - accuracy: 0.8321 - val_loss: 0.3342 - val_accuracy: 0.8306\n",
      "Epoch 118/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8311 - val_loss: 0.3350 - val_accuracy: 0.8368\n",
      "Epoch 119/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3330 - accuracy: 0.8326 - val_loss: 0.3342 - val_accuracy: 0.8397\n",
      "Epoch 120/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3330 - accuracy: 0.8337 - val_loss: 0.3322 - val_accuracy: 0.8375\n",
      "Epoch 121/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3328 - accuracy: 0.8339 - val_loss: 0.3325 - val_accuracy: 0.8381\n",
      "Epoch 122/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3323 - accuracy: 0.8320 - val_loss: 0.3423 - val_accuracy: 0.8267\n",
      "Epoch 123/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3322 - accuracy: 0.8333 - val_loss: 0.3321 - val_accuracy: 0.8405\n",
      "Epoch 124/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3316 - accuracy: 0.8330 - val_loss: 0.3351 - val_accuracy: 0.8366\n",
      "Epoch 125/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3315 - accuracy: 0.8348 - val_loss: 0.3369 - val_accuracy: 0.8268\n",
      "Epoch 126/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3315 - accuracy: 0.8345 - val_loss: 0.3309 - val_accuracy: 0.8386\n",
      "Epoch 127/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3307 - accuracy: 0.8331 - val_loss: 0.3317 - val_accuracy: 0.8381\n",
      "Epoch 128/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3301 - accuracy: 0.8361 - val_loss: 0.3334 - val_accuracy: 0.8325\n",
      "Epoch 129/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3306 - accuracy: 0.8331 - val_loss: 0.3315 - val_accuracy: 0.8365\n",
      "Epoch 130/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3300 - accuracy: 0.8340 - val_loss: 0.3303 - val_accuracy: 0.8402\n",
      "Epoch 131/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3297 - accuracy: 0.8345 - val_loss: 0.3313 - val_accuracy: 0.8308\n",
      "Epoch 132/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3298 - accuracy: 0.8341 - val_loss: 0.3317 - val_accuracy: 0.8338\n",
      "Epoch 133/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3300 - accuracy: 0.8337 - val_loss: 0.3328 - val_accuracy: 0.8340\n",
      "Epoch 134/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3296 - accuracy: 0.8338 - val_loss: 0.3312 - val_accuracy: 0.8388\n",
      "Epoch 135/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3290 - accuracy: 0.8346 - val_loss: 0.3293 - val_accuracy: 0.8359\n",
      "Epoch 136/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3294 - accuracy: 0.8344 - val_loss: 0.3325 - val_accuracy: 0.8420\n",
      "Epoch 137/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3288 - accuracy: 0.8360 - val_loss: 0.3292 - val_accuracy: 0.8373\n",
      "Epoch 138/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3282 - accuracy: 0.8352 - val_loss: 0.3348 - val_accuracy: 0.8382\n",
      "Epoch 139/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3279 - accuracy: 0.8344 - val_loss: 0.3297 - val_accuracy: 0.8347\n",
      "Epoch 140/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3276 - accuracy: 0.8335 - val_loss: 0.3314 - val_accuracy: 0.8402\n",
      "Epoch 141/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8356 - val_loss: 0.3281 - val_accuracy: 0.8413\n",
      "Epoch 142/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.8366 - val_loss: 0.3299 - val_accuracy: 0.8363\n",
      "Epoch 143/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3276 - accuracy: 0.8351 - val_loss: 0.3275 - val_accuracy: 0.8391\n",
      "Epoch 144/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3264 - accuracy: 0.8356 - val_loss: 0.3286 - val_accuracy: 0.8398\n",
      "Epoch 145/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3267 - accuracy: 0.8355 - val_loss: 0.3271 - val_accuracy: 0.8427\n",
      "Epoch 146/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.3263 - accuracy: 0.8361 - val_loss: 0.3311 - val_accuracy: 0.8332\n",
      "Epoch 147/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3262 - accuracy: 0.8377 - val_loss: 0.3262 - val_accuracy: 0.8382\n",
      "Epoch 148/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3257 - accuracy: 0.8379 - val_loss: 0.3284 - val_accuracy: 0.8363\n",
      "Epoch 149/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8355 - val_loss: 0.3254 - val_accuracy: 0.8398\n",
      "Epoch 150/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3255 - accuracy: 0.8360 - val_loss: 0.3348 - val_accuracy: 0.8293\n",
      "Epoch 151/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3257 - accuracy: 0.8367 - val_loss: 0.3260 - val_accuracy: 0.8427\n",
      "Epoch 152/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3252 - accuracy: 0.8368 - val_loss: 0.3275 - val_accuracy: 0.8373\n",
      "Epoch 153/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3251 - accuracy: 0.8371 - val_loss: 0.3290 - val_accuracy: 0.8420\n",
      "Epoch 154/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3248 - accuracy: 0.8381 - val_loss: 0.3275 - val_accuracy: 0.8363\n",
      "Epoch 155/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3241 - accuracy: 0.8378 - val_loss: 0.3293 - val_accuracy: 0.8354\n",
      "Epoch 156/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3247 - accuracy: 0.8390 - val_loss: 0.3280 - val_accuracy: 0.8361\n",
      "Epoch 157/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3244 - accuracy: 0.8382 - val_loss: 0.3262 - val_accuracy: 0.8347\n",
      "Epoch 158/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3243 - accuracy: 0.8396 - val_loss: 0.3277 - val_accuracy: 0.8427\n",
      "Epoch 159/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.3241 - accuracy: 0.8374 - val_loss: 0.3285 - val_accuracy: 0.8381\n",
      "Epoch 160/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.3240 - accuracy: 0.8401 - val_loss: 0.3265 - val_accuracy: 0.8366\n",
      "Epoch 161/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.3238 - accuracy: 0.8393 - val_loss: 0.3256 - val_accuracy: 0.8366\n",
      "Epoch 161: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a1bdae5c8>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train, validation_data=(X_test, y_test), epochs=400, batch_size=128, \n",
    "          callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df = pd.DataFrame(model.history.history)\n",
    "loss_df[['loss', 'val_loss']].plot(legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_with_dropout():\n",
    "    model = keras.Sequential(name=\"classification_model_with_Dropout\")\n",
    "    model.add(layers.Input(shape=(X_train.shape[1],)))  \n",
    "    model.add(layers.Dense(units = 20, activation = 'relu', name=\"first_layer\"))\n",
    "    model.add(layers.Dropout(rate=0.5))  \n",
    "    \n",
    "    model.add(layers.Dense(units = 8, activation = 'relu', name=\"second_layer\"))\n",
    "    model.add(layers.Dropout(rate=0.5))\n",
    "    \n",
    "    \n",
    "    model.add(layers.Dense(units = 1, activation = 'sigmoid', name=\"output_layer\"))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classification_model_with_Dropout\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " first_layer (Dense)         (None, 20)                140       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " second_layer (Dense)        (None, 8)                 168       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 317\n",
      "Trainable params: 317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_with_dropout = build_model_with_dropout()\n",
    "model_with_dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "176/176 [==============================] - 2s 4ms/step - loss: 0.7061 - accuracy: 0.5422 - val_loss: 0.6418 - val_accuracy: 0.6560\n",
      "Epoch 2/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.6505 - accuracy: 0.6051 - val_loss: 0.6029 - val_accuracy: 0.6850\n",
      "Epoch 3/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.6264 - accuracy: 0.6415 - val_loss: 0.5791 - val_accuracy: 0.7028\n",
      "Epoch 4/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.6132 - accuracy: 0.6574 - val_loss: 0.5604 - val_accuracy: 0.7260\n",
      "Epoch 5/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5984 - accuracy: 0.6783 - val_loss: 0.5458 - val_accuracy: 0.7321\n",
      "Epoch 6/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5919 - accuracy: 0.6823 - val_loss: 0.5391 - val_accuracy: 0.7404\n",
      "Epoch 7/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5835 - accuracy: 0.6916 - val_loss: 0.5338 - val_accuracy: 0.7347\n",
      "Epoch 8/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.5792 - accuracy: 0.6913 - val_loss: 0.5283 - val_accuracy: 0.7395\n",
      "Epoch 9/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5758 - accuracy: 0.6987 - val_loss: 0.5236 - val_accuracy: 0.7429\n",
      "Epoch 10/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.5707 - accuracy: 0.6979 - val_loss: 0.5188 - val_accuracy: 0.7404\n",
      "Epoch 11/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.5616 - accuracy: 0.7030 - val_loss: 0.5110 - val_accuracy: 0.7545\n",
      "Epoch 12/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5590 - accuracy: 0.7076 - val_loss: 0.5088 - val_accuracy: 0.7525\n",
      "Epoch 13/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5554 - accuracy: 0.7137 - val_loss: 0.5059 - val_accuracy: 0.7538\n",
      "Epoch 14/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5528 - accuracy: 0.7118 - val_loss: 0.5011 - val_accuracy: 0.7524\n",
      "Epoch 15/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5496 - accuracy: 0.7120 - val_loss: 0.4972 - val_accuracy: 0.7508\n",
      "Epoch 16/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5481 - accuracy: 0.7125 - val_loss: 0.4964 - val_accuracy: 0.7522\n",
      "Epoch 17/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5437 - accuracy: 0.7174 - val_loss: 0.4934 - val_accuracy: 0.7515\n",
      "Epoch 18/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5449 - accuracy: 0.7161 - val_loss: 0.4927 - val_accuracy: 0.7488\n",
      "Epoch 19/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5408 - accuracy: 0.7164 - val_loss: 0.4902 - val_accuracy: 0.7559\n",
      "Epoch 20/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5413 - accuracy: 0.7177 - val_loss: 0.4879 - val_accuracy: 0.7552\n",
      "Epoch 21/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5408 - accuracy: 0.7179 - val_loss: 0.4857 - val_accuracy: 0.7525\n",
      "Epoch 22/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5363 - accuracy: 0.7217 - val_loss: 0.4840 - val_accuracy: 0.7568\n",
      "Epoch 23/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7204 - val_loss: 0.4826 - val_accuracy: 0.7538\n",
      "Epoch 24/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5372 - accuracy: 0.7210 - val_loss: 0.4831 - val_accuracy: 0.7525\n",
      "Epoch 25/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5339 - accuracy: 0.7221 - val_loss: 0.4808 - val_accuracy: 0.7538\n",
      "Epoch 26/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7223 - val_loss: 0.4814 - val_accuracy: 0.7534\n",
      "Epoch 27/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5324 - accuracy: 0.7241 - val_loss: 0.4801 - val_accuracy: 0.7509\n",
      "Epoch 28/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5334 - accuracy: 0.7201 - val_loss: 0.4792 - val_accuracy: 0.7543\n",
      "Epoch 29/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5325 - accuracy: 0.7219 - val_loss: 0.4775 - val_accuracy: 0.7506\n",
      "Epoch 30/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5307 - accuracy: 0.7227 - val_loss: 0.4783 - val_accuracy: 0.7472\n",
      "Epoch 31/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5297 - accuracy: 0.7205 - val_loss: 0.4776 - val_accuracy: 0.7520\n",
      "Epoch 32/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7246 - val_loss: 0.4780 - val_accuracy: 0.7493\n",
      "Epoch 33/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7235 - val_loss: 0.4738 - val_accuracy: 0.7584\n",
      "Epoch 34/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5282 - accuracy: 0.7264 - val_loss: 0.4754 - val_accuracy: 0.7509\n",
      "Epoch 35/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5288 - accuracy: 0.7254 - val_loss: 0.4748 - val_accuracy: 0.7559\n",
      "Epoch 36/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5276 - accuracy: 0.7242 - val_loss: 0.4740 - val_accuracy: 0.7527\n",
      "Epoch 37/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5248 - accuracy: 0.7216 - val_loss: 0.4724 - val_accuracy: 0.7549\n",
      "Epoch 38/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5273 - accuracy: 0.7221 - val_loss: 0.4738 - val_accuracy: 0.7499\n",
      "Epoch 39/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.5278 - accuracy: 0.7242 - val_loss: 0.4731 - val_accuracy: 0.7586\n",
      "Epoch 40/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5261 - accuracy: 0.7299 - val_loss: 0.4740 - val_accuracy: 0.7561\n",
      "Epoch 41/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.5281 - accuracy: 0.7250 - val_loss: 0.4750 - val_accuracy: 0.7531\n",
      "Epoch 42/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5277 - accuracy: 0.7249 - val_loss: 0.4718 - val_accuracy: 0.7556\n",
      "Epoch 43/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5248 - accuracy: 0.7264 - val_loss: 0.4736 - val_accuracy: 0.7556\n",
      "Epoch 44/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5249 - accuracy: 0.7236 - val_loss: 0.4722 - val_accuracy: 0.7549\n",
      "Epoch 45/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.5220 - accuracy: 0.7276 - val_loss: 0.4718 - val_accuracy: 0.7533\n",
      "Epoch 46/400\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.5249 - accuracy: 0.7237 - val_loss: 0.4721 - val_accuracy: 0.7541\n",
      "Epoch 47/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5226 - accuracy: 0.7256 - val_loss: 0.4696 - val_accuracy: 0.7572\n",
      "Epoch 48/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5231 - accuracy: 0.7226 - val_loss: 0.4724 - val_accuracy: 0.7540\n",
      "Epoch 49/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5240 - accuracy: 0.7275 - val_loss: 0.4708 - val_accuracy: 0.7625\n",
      "Epoch 50/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5238 - accuracy: 0.7264 - val_loss: 0.4679 - val_accuracy: 0.7563\n",
      "Epoch 51/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5241 - accuracy: 0.7273 - val_loss: 0.4690 - val_accuracy: 0.7538\n",
      "Epoch 52/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5201 - accuracy: 0.7291 - val_loss: 0.4693 - val_accuracy: 0.7570\n",
      "Epoch 53/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5216 - accuracy: 0.7298 - val_loss: 0.4690 - val_accuracy: 0.7533\n",
      "Epoch 54/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7288 - val_loss: 0.4690 - val_accuracy: 0.7525\n",
      "Epoch 55/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5221 - accuracy: 0.7291 - val_loss: 0.4674 - val_accuracy: 0.7534\n",
      "Epoch 56/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7275 - val_loss: 0.4677 - val_accuracy: 0.7533\n",
      "Epoch 57/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5204 - accuracy: 0.7280 - val_loss: 0.4680 - val_accuracy: 0.7516\n",
      "Epoch 58/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7285 - val_loss: 0.4663 - val_accuracy: 0.7540\n",
      "Epoch 59/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5206 - accuracy: 0.7265 - val_loss: 0.4668 - val_accuracy: 0.7529\n",
      "Epoch 60/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7270 - val_loss: 0.4671 - val_accuracy: 0.7565\n",
      "Epoch 61/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.7289 - val_loss: 0.4663 - val_accuracy: 0.7609\n",
      "Epoch 62/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7297 - val_loss: 0.4671 - val_accuracy: 0.7584\n",
      "Epoch 63/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5197 - accuracy: 0.7281 - val_loss: 0.4686 - val_accuracy: 0.7563\n",
      "Epoch 64/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5190 - accuracy: 0.7331 - val_loss: 0.4688 - val_accuracy: 0.7513\n",
      "Epoch 65/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5169 - accuracy: 0.7254 - val_loss: 0.4666 - val_accuracy: 0.7538\n",
      "Epoch 66/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5150 - accuracy: 0.7275 - val_loss: 0.4648 - val_accuracy: 0.7563\n",
      "Epoch 67/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5157 - accuracy: 0.7284 - val_loss: 0.4650 - val_accuracy: 0.7598\n",
      "Epoch 68/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5176 - accuracy: 0.7272 - val_loss: 0.4668 - val_accuracy: 0.7570\n",
      "Epoch 69/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5199 - accuracy: 0.7277 - val_loss: 0.4673 - val_accuracy: 0.7552\n",
      "Epoch 70/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5150 - accuracy: 0.7290 - val_loss: 0.4669 - val_accuracy: 0.7543\n",
      "Epoch 71/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7260 - val_loss: 0.4661 - val_accuracy: 0.7561\n",
      "Epoch 72/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7261 - val_loss: 0.4670 - val_accuracy: 0.7568\n",
      "Epoch 73/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7268 - val_loss: 0.4681 - val_accuracy: 0.7529\n",
      "Epoch 74/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5190 - accuracy: 0.7239 - val_loss: 0.4643 - val_accuracy: 0.7584\n",
      "Epoch 75/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5182 - accuracy: 0.7288 - val_loss: 0.4647 - val_accuracy: 0.7595\n",
      "Epoch 76/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5192 - accuracy: 0.7256 - val_loss: 0.4645 - val_accuracy: 0.7613\n",
      "Epoch 77/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7255 - val_loss: 0.4677 - val_accuracy: 0.7565\n",
      "Epoch 78/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5176 - accuracy: 0.7266 - val_loss: 0.4686 - val_accuracy: 0.7593\n",
      "Epoch 79/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5188 - accuracy: 0.7230 - val_loss: 0.4668 - val_accuracy: 0.7572\n",
      "Epoch 80/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5183 - accuracy: 0.7281 - val_loss: 0.4643 - val_accuracy: 0.7588\n",
      "Epoch 81/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5224 - accuracy: 0.7244 - val_loss: 0.4650 - val_accuracy: 0.7586\n",
      "Epoch 82/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5178 - accuracy: 0.7267 - val_loss: 0.4651 - val_accuracy: 0.7577\n",
      "Epoch 83/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5148 - accuracy: 0.7298 - val_loss: 0.4649 - val_accuracy: 0.7590\n",
      "Epoch 84/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7264 - val_loss: 0.4635 - val_accuracy: 0.7602\n",
      "Epoch 85/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.7303 - val_loss: 0.4653 - val_accuracy: 0.7527\n",
      "Epoch 86/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7249 - val_loss: 0.4638 - val_accuracy: 0.7591\n",
      "Epoch 87/400\n",
      "176/176 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.7260 - val_loss: 0.4634 - val_accuracy: 0.7563\n",
      "Epoch 88/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7287 - val_loss: 0.4649 - val_accuracy: 0.7534\n",
      "Epoch 89/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5198 - accuracy: 0.7237 - val_loss: 0.4679 - val_accuracy: 0.7504\n",
      "Epoch 90/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7263 - val_loss: 0.4641 - val_accuracy: 0.7591\n",
      "Epoch 91/400\n",
      "176/176 [==============================] - 1s 3ms/step - loss: 0.5196 - accuracy: 0.7248 - val_loss: 0.4619 - val_accuracy: 0.7597\n",
      "Epoch 92/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7275 - val_loss: 0.4634 - val_accuracy: 0.7565\n",
      "Epoch 93/400\n",
      "176/176 [==============================] - 0s 3ms/step - loss: 0.5172 - accuracy: 0.7271 - val_loss: 0.4664 - val_accuracy: 0.7556\n",
      "Epoch 94/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5150 - accuracy: 0.7300 - val_loss: 0.4635 - val_accuracy: 0.7566\n",
      "Epoch 95/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5173 - accuracy: 0.7297 - val_loss: 0.4651 - val_accuracy: 0.7543\n",
      "Epoch 96/400\n",
      "176/176 [==============================] - 1s 8ms/step - loss: 0.5167 - accuracy: 0.7276 - val_loss: 0.4630 - val_accuracy: 0.7604\n",
      "Epoch 97/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.5149 - accuracy: 0.7282 - val_loss: 0.4631 - val_accuracy: 0.7600\n",
      "Epoch 98/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5143 - accuracy: 0.7295 - val_loss: 0.4630 - val_accuracy: 0.7609\n",
      "Epoch 99/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.5167 - accuracy: 0.7252 - val_loss: 0.4643 - val_accuracy: 0.7606\n",
      "Epoch 100/400\n",
      "176/176 [==============================] - 1s 5ms/step - loss: 0.5156 - accuracy: 0.7248 - val_loss: 0.4630 - val_accuracy: 0.7597\n",
      "Epoch 101/400\n",
      "176/176 [==============================] - 1s 4ms/step - loss: 0.5185 - accuracy: 0.7302 - val_loss: 0.4619 - val_accuracy: 0.7623\n",
      "Epoch 102/400\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.5165 - accuracy: 0.7252 - val_loss: 0.4627 - val_accuracy: 0.7497\n",
      "Epoch 103/400\n",
      "176/176 [==============================] - 1s 6ms/step - loss: 0.5141 - accuracy: 0.7251 - val_loss: 0.4638 - val_accuracy: 0.7584\n",
      "Epoch 103: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a1f032f48>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_dropout.fit(X_train,y_train, validation_data=(X_test, y_test), epochs=400, batch_size=128, \n",
    "          callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_df_with_dropout = pd.DataFrame(model_with_dropout.history.history)\n",
    "loss_df_with_dropout[['loss', 'val_loss']].plot(legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.32555991411209106, 0.8366292715072632]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.7584\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.46380025148391724, 0.7584179639816284]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_dropout.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_probs = model_with_dropout.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0759255],\n",
       "       [0.4595828],\n",
       "       [0.9971913],\n",
       "       ...,\n",
       "       [0.9466976],\n",
       "       [0.5317599],\n",
       "       [0.951363 ]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_probs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_test_probs</th>\n",
       "      <th>y_test_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.075925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.459583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.997191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.631050</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   y_test  y_test_probs  y_test_predictions\n",
       "0       0      0.075925                   0\n",
       "1       0      0.459583                   0\n",
       "2       1      0.997191                   1\n",
       "3       1      1.000000                   1\n",
       "4       0      0.631050                   1"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.DataFrame({\"y_test\":y_test, \"y_test_probs\":y_test_probs.reshape(-1,)})\n",
    "predictions['y_test_predictions']= np.where(predictions['y_test_probs']>0.5,1,0)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.63      0.71      2668\n",
      "           1       0.72      0.87      0.79      2945\n",
      "\n",
      "    accuracy                           0.76      5613\n",
      "   macro avg       0.77      0.75      0.75      5613\n",
      "weighted avg       0.77      0.76      0.75      5613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true= predictions.y_test, y_pred=predictions.y_test_predictions) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1692  976]\n",
      " [ 380 2565]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_true= predictions.y_test, y_pred=predictions.y_test_predictions) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DNN_classification\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DNN_classification\\assets\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DNN_withDropout_classification\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: DNN_withDropout_classification\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('DNN_classification')\n",
    "model_with_dropout.save('DNN_withDropout_classification')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('DNN_classification')\n",
    "loaded_model_with_Dropout = load_model('DNN_withDropout_classification')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classification_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " first_layer (Dense)         (None, 20)                140       \n",
      "                                                                 \n",
      " second_layer (Dense)        (None, 8)                 168       \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 317\n",
      "Trainable params: 317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.1548282e-22],\n",
       "       [2.2239926e-01],\n",
       "       [9.9694055e-01],\n",
       "       ...,\n",
       "       [9.9269426e-01],\n",
       "       [5.5077857e-01],\n",
       "       [9.9337369e-01]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classification_model_with_Dropout\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " first_layer (Dense)         (None, 20)                140       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 20)                0         \n",
      "                                                                 \n",
      " second_layer (Dense)        (None, 8)                 168       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 8)                 0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 317\n",
      "Trainable params: 317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model_with_Dropout.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"classification_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " first_layer (Dense)         (None, 20)                140       \n",
      "                                                                 \n",
      " second_layer (Dense)        (None, 8)                 168       \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 317\n",
      "Trainable params: 317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_checkpoint = load_model(\"model_checkpoint.keras\")\n",
    "loaded_checkpoint.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
